<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Diary | Federico Maggi</title>
    <link>/post/</link>
      <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Diary</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>©2009–2025. All rights are reserved to Federico Maggi or the respective authors. Opinions are my own, and not necessarily reflecting the views of my employer. </copyright><lastBuildDate>Mon, 15 Nov 2021 21:41:54 +0100</lastBuildDate>
    <image>
      <url>/images/icon_hu16868671553544422563.png</url>
      <title>Diary</title>
      <link>/post/</link>
    </image>
    
    <item>
      <title>Scalable, Hand-curated Newsletters: A Data-centric, Automatic Workflow</title>
      <link>/post/scalable-handcurated-newsletter/</link>
      <pubDate>Mon, 15 Nov 2021 21:41:54 +0100</pubDate>
      <guid>/post/scalable-handcurated-newsletter/</guid>
      <description>&lt;p&gt;I guess it&amp;rsquo;s not unique to the cyber-security world, but research and media move pretty fast here, so it&amp;rsquo;s easy to end up with hundreds of seemingly interestingly articles or blog posts to read every day. Of course, that&amp;rsquo;s not humanly possible. Let me tell you how I deal with this with only two tools, 
&lt;a href=&#34;https://inoreader.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Inoreader&lt;/a&gt; and 
&lt;a href=&#34;https://zotero.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zotero&lt;/a&gt;, plus some scripting.&lt;/p&gt;
&lt;p&gt;In 
&lt;a href=&#34;/cyberfacts/issue-3/&#34;&gt;CyberFacts Weekly Issue 0x03&lt;/a&gt; I briefly hinted about this workflow, which surprisingly have inspired one of my subscribers to follow the same approach to curate their own newsletter (cool!). This motivated me to spend some time and write down the details of the workflow, in the hope that curators and newsletter authors would find it useful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DISCLAIMER:&lt;/strong&gt; I don&amp;rsquo;t care about building an audience nor monetizing this. I do this to fuel my thirst for research ideas. Admittedly, I like to pretend there is an audience, which keeps me motivated to keep maintaining this.&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#why-curated-content&#34;&gt;Why Curated Content?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#no-silver-bullet-curation&#34;&gt;No Silver Bullet Curation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#from-consuming-to-creating&#34;&gt;From Consuming to Creating&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#high-level-pseudo-workflow-no-tools-yet&#34;&gt;High-Level Pseudo Workflow: No Tools, Yet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#from-research-to-headline-a-simplified-journey&#34;&gt;From Research to Headline: A Simplified Journey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#the-workflow-for-the-impatient&#34;&gt;The Workflow: For the Impatient&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#sourcing-discovering-organizing-and-consuming-good-sources-1-2&#34;&gt;Sourcing: Discovering, Organizing, and Consuming Good Sources (1-2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#taxonomy-tagging-skimming-selection-2&#34;&gt;Taxonomy, tagging, skimming, selection (2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#live-sharing-with-minimum-friction-3&#34;&gt;Live Sharing With Minimum Friction (3)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#reading-curation-annotation-summary-4&#34;&gt;Reading, curation, annotation, summary (4)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#weekly-digest-sharing-5&#34;&gt;Weekly digest sharing (5)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#whats-left&#34;&gt;What&amp;rsquo;s Left?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;why-curated-content&#34;&gt;Why Curated Content?&lt;/h2&gt;
&lt;p&gt;Good research starts with good knowledge of the environment, state of the art, and key people. I guess it&amp;rsquo;s not unique to the cyber-security world, but &lt;strong&gt;research and media move pretty fast&lt;/strong&gt; in this field, so it&amp;rsquo;s easy to end up with hundreds of seemingly interestingly articles or blog posts to read every day. Of course, that&amp;rsquo;s not humanly possible. And this is without including social media and fake news &amp;ldquo;drifts&amp;rdquo; in the picture.&lt;/p&gt;
&lt;p&gt;Hand curation services and newsletters have became very popular as a mean for &lt;strong&gt;busy people&lt;/strong&gt; to stay on top of things, letting curators filter noise from the signal: 
&lt;a href=&#34;https://lists.cymru.com/mailman/options/dragon_newsbytes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dragon News Bytes (DNB)&lt;/a&gt;, 
&lt;a href=&#34;https://www.sans.org/newsletters/newsbites/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SANS Newsbites&lt;/a&gt;, 
&lt;a href=&#34;https://danielmiessler.com/newsletter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsupervised Learning&lt;/a&gt;, 
&lt;a href=&#34;https://tldrsec.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tl;dr sec&lt;/a&gt;, 
&lt;a href=&#34;https://cloudseclist.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CloudSecList&lt;/a&gt;, and 
&lt;a href=&#34;https://guerredirete.substack.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Guerre di Rete&lt;/a&gt; are some of those I read.&lt;/p&gt;
&lt;h2 id=&#34;no-silver-bullet-curation&#34;&gt;No Silver Bullet Curation&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;ve learned there&amp;rsquo;s &lt;strong&gt;no silver bullet&lt;/strong&gt; in content curation: Some of these digests are lightly processed, some are more processed and include analyses, some fit my research topics, some completely miss some key stories I need to know about. Some newsletters are too high level (but contain good pointers!), while some other newsletters are too narrow.&lt;/p&gt;
&lt;p&gt;While there are some must-read stories every week (which are found in the set-intersection between all good newsletters), each one of us has their own style and need to build their own opinion, independently, through autonomous content sourcing. Regardless of how good some newsletters are, even paid ones, I&amp;rsquo;ve always ended up not finding something I wanted in each one of them. So, while being an avid consumer of newsletters, a few years ago, I felt the need to understand more of how research results develop into news stories as a mean to build my own view. After all, traditional media outlets and socials cover a very important and critical role of research dissemination, with the responsibility of making the difference on public opinion around a cold research result.&lt;/p&gt;
&lt;h2 id=&#34;from-consuming-to-creating&#34;&gt;From Consuming to Creating&lt;/h2&gt;
&lt;p&gt;I decided I wanted to get to the source of each news I read. So, I started to systematize my reading list into a taxonomy and, month over month, I&amp;rsquo;ve been feeling I&amp;rsquo;d improved the way I consume readings, gaining more confidence in the difficult task of telling apart interesting from non-interesting news stories. I mean, interesting for my work, of course. Sometimes my work is interesting to the public, so, very seldom, &lt;em&gt;my&lt;/em&gt; noteworthy news stories are interesting for others, too.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/cf-overall.png&#34; alt=&#34;Overall workflow&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let me now tell you how I deal with the ever-growing amount of reading material, having only a few minutes a day, often with more important work-related tasks to do.&lt;/p&gt;
&lt;h2 id=&#34;high-level-pseudo-workflow-no-tools-yet&#34;&gt;High-Level Pseudo Workflow: No Tools, Yet&lt;/h2&gt;
&lt;p&gt;Without going down into the tooling and details, yet, my workflow can be boiled down to the following steps.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Sources of content:&lt;/strong&gt; newspapers, mainstream media outlets, press releases, official and personal blogs, public and private social media feeds, bulletins, content aggregators, other curated content. I organize my sources in a taxonomy with overlapping categories (e.g., a source can be both marked as &amp;ldquo;Must read&amp;rdquo; as well be in a broader &amp;ldquo;Infosec Relevant&amp;rdquo; category), by topic, and by importance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Discovery of new sources:&lt;/strong&gt; when I encounter an interesting story (e.g., shared by someone else via social media) and I notice I didn&amp;rsquo;t know about that source, I find a place for it within my taxonomy of sources.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Systematize and prioritize sources &amp;amp; topics:&lt;/strong&gt; every time I feel I can&amp;rsquo;t find a good place for a new source, I revise my taxonomy of sources, get rid of inactive or noisy sources, re-sort, etc. I organize my taxonomy in sorted folders from the most important topic-folders (top) to the most generic ones (bottom). In 3 years I&amp;rsquo;ve done this spring cleaning probably twice, so it&amp;rsquo;s not a lot of work.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Automatic filtering, &amp;ldquo;bucketization,&amp;rdquo; and tagging:&lt;/strong&gt; All items are first globally de-duplicated (so that I don&amp;rsquo;t happen to read the same item twice, not even by accident), slightly filtered to reduce noise (e.g., I&amp;rsquo;m not interested in Q&amp;amp;As or AMA posts on Reddit, replies to Tweets), bucketized into topic-folders, and automatically tagged for interesting keywords (e.g., tracked topics, people, places, software names).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Skimming through buckets:&lt;/strong&gt; The way my sources are organized is such that I don&amp;rsquo;t have to choose what to read. The top buckets will always appear at the top, and as I mark them as read, they&amp;rsquo;ll disappear from the current bucket, and from any other overlapping buckets below.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Select interesting articles:&lt;/strong&gt; When I find an interesting item, I tag it as &amp;ldquo;Noteworthy,&amp;rdquo; which triggers automatic archival and immediate sharing (e.g., on Twitter). I have private chats with co-workers where I share the same (or slightly different) content. I create one tag for each one of these cases so I can manage their workflows independently.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Share and track:&lt;/strong&gt; When the content get shared via my social media channels, I receive notifications when people comment, re-share, or like, which gives me an indication of how good my choice was. Also, when I select an item about a completely new (but very important) topic, I setup auto-tagging of that topic, so that I get notified when something about that topic pops in the news again.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sort content selection:&lt;/strong&gt; Every 1-2 days, I go through my &amp;ldquo;Noteworthy&amp;rdquo; items and, also based on feedback from social media (if any), I choose the absolutely most important items and read through them in my browser.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Annotate selected content:&lt;/strong&gt; While reading, I take an HTML snapshot and save a copy of the page so that I can annotate and archive locally.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight and summarize:&lt;/strong&gt; While reading, I highlight the most important pieces and start thinking about a one-liner to summarize the story, which may happen to be the same title chosen by the original reporter.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Digest:&lt;/strong&gt; Every week, I spend 30&amp;rsquo; to organize the selected content into 3+ groups: top most important items, also important, tools, and some other ad-hoc groups (e.g., vulnerabilities) as the content demands.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Share:&lt;/strong&gt; From the weekly selection, I have automatic scripts that generate a Markdown file containing an intro I write (there go my 30&amp;rsquo;), table of content, summary, and list of grouped items; that file is then converted into HTML and summaries for Twitter and LinkedIn.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Maintain:&lt;/strong&gt; And that used to be the hardest part, but most of this workflow is automated, so I can focus of what I&amp;rsquo;d do anyhow: reading!&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;from-research-to-headline-a-simplified-journey&#34;&gt;From Research to Headline: A Simplified Journey&lt;/h2&gt;
&lt;p&gt;At times my work gets picked up &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; by the media, so I&amp;rsquo;ve seen how things work from both sides of the journey. What follows is not the complete picture, but just a quick summary as a pre-requisite to better appreciate the rest of this post.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/cf-research-headline.png&#34; alt=&#34;From research to headline&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the diagram above you can see the changes induced by massive use of social media. Despite the simplicity of the diagram, the effects are relevant.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Idea genesis:&lt;/strong&gt; Researchers have ideas all the time, while discussing with colleagues or reading others&amp;rsquo; work. Due to resource constraints, not all ideas get developed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Research development:&lt;/strong&gt; Research ideas are developed into research projects, which ultimately lead to results (good or bad). Some results are written into more or less scientific reports or white papers for the general public or special interest groups.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embargoed content and press releases:&lt;/strong&gt; If a researcher (or their organization) deems that a research result is important and want to make mediatic noise about it, they can decide to contact a trusted reporter, directly or indirectly, or prepare a press release (the latter is the norm for large organizations). The same concept applies to coordinated vulnerability disclosure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Public peer-reviewed publication or conference talk about results:&lt;/strong&gt; Independently from, but usually in coordination with, release via media outlets, original and important research results are submitted for reviewed venues (e.g., scientific or non scientific conferences), which may end up selecting them for publication, usually including a public speech.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;First media article publication:&lt;/strong&gt; Depending on the agreements with the reporters, the cat gets out of the sac. The research becomes public news, although who needed to know (e.g., target of an attack, vendors of a vulnerable product, breached account holders) already knew, which creates the possibility of leaks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Follow-up news articles:&lt;/strong&gt; Other reporters discover about interesting articles and write their own take, potentially interviewing other experts, develop other angles of the story, make connections, etc. This creates many near-duplicates or updates to te original story.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Social amplification and content aggregation:&lt;/strong&gt; The many verses have their say about relevant news, and usually comment a lot when something interesting pops up, create aggregation pages, and so on.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Readers content consumption:&lt;/strong&gt; Finally, the readers, the intended audience, gets a chance to read the original story, or one of the many derivatives.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And we&amp;rsquo;re here, we&amp;rsquo;re all content consumers. Some of us are producers, but we can&amp;rsquo;t just not being consumers. Content creators and curators, especially if they&amp;rsquo;re subject matter experts (SME), want to go the source of a content, potentially all the way back to the original research material. I think this is the key to good content curation: Find the right balance between looking at the source while listening to output of the following steps. Or, in other words, it&amp;rsquo;s important to follow a reporter, but even the best reporters can make mistakes or omit details because they need to summarize.&lt;/p&gt;
&lt;h2 id=&#34;the-workflow-for-the-impatient&#34;&gt;The Workflow: For the Impatient&lt;/h2&gt;
&lt;p&gt;It&amp;rsquo;s now time to dig into the details of how we can start curating our interesting content. From now on, I&amp;rsquo;ll write about the tools and approaches that I use.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/0-inoreader-main.png&#34; alt=&#34;Inoreader main&#34;&gt;&lt;/p&gt;
&lt;p&gt;I use Inoreader for 99% of my readings and archival, and Zotero for local archival and newsletter editing. Inspired by Marco Lancini&amp;rsquo;s CloudSecList, which 
&lt;a href=&#34;https://www.marcolancini.it/2020/blog-serverless-mailing-list/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;uses a JSON file&lt;/a&gt; to hold the data of each issue, I use Zotero&amp;rsquo;s auto-generated JSON files for the same purpose, with some post-processing.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/cf-high-level-workflow.png&#34; alt=&#34;Workflow&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;sourcing-discovering-organizing-and-consuming-good-sources-1-2&#34;&gt;Sourcing: Discovering, Organizing, and Consuming Good Sources (1-2)&lt;/h3&gt;
&lt;p&gt;My sources include global and local newspapers (there&amp;rsquo;s more than just cyber-security), mainstream media outlets, press releases, official and personal blogs, public and private social media feeds, bulletins, content aggregators, other curated content. Roughly, I split sources in the following macro groups:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;New sources&lt;/strong&gt; I monitor to see how I like them; this group include newly discovered sources that I put in &amp;ldquo;beta testing&amp;rdquo;; usually, they stay in this group for a few weeks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Top stuff&lt;/strong&gt; I absolutely must read; this group includes RSS feeds from renowned voices in the cyber-security field (e.g., Bruce Schneier, Brian Krebs), top outlets (e.g., Engaged, WIRED, Forbes), top technical blogs (e.g., Google Project Zero), etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Specialized sources&lt;/strong&gt; that are relevant and low-noise, but one step after the top sources; this include newsletters or digests, the 
&lt;a href=&#34;https://reddit.com/r/netsec&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r/netsec&lt;/a&gt; sub-reddit, 
&lt;a href=&#34;https://www.techmeme.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Techmeme&lt;/a&gt;, pure feeds (e.g., vulnerability feeds, news from law enforcements), and press releases from top tech companies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-specialized sources&lt;/strong&gt;, which include tech outlets like Gizmodo, Engaged, hand-curated world news (e.g., via 
&lt;a href=&#34;https://www.mediagazer.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mediagazer&lt;/a&gt;), personal blogs, trending GitHub repositories, official blogs of top tech companies, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;All the rest&lt;/strong&gt;. Why do I keep this? First of all because I want to be able to globally search on everything. Secondly, if a news is really important, it will travel far, far away, event to the local free newspaper. So, monitoring the least-popular sources will give you indirect confirmation that something is &lt;em&gt;really&lt;/em&gt; good, if you know how to interpret signals.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/1-inoreader-tech-blogs.png&#34; alt=&#34;Inoreader tech blogs&#34;&gt;&lt;/p&gt;
&lt;p&gt;I organize my sources in a taxonomy with overlapping categories (e.g., a source can be both marked as &amp;ldquo;Must read&amp;rdquo; as well be in a broader &amp;ldquo;Infosec Relevant&amp;rdquo; category), by topic, and by importance.&lt;/p&gt;
&lt;p&gt;When I encounter an interesting story (e.g., shared by someone else via social media) and I notice I didn&amp;rsquo;t know about that source, I find a place for it within my taxonomy of sources.&lt;/p&gt;
&lt;h3 id=&#34;taxonomy-tagging-skimming-selection-2&#34;&gt;Taxonomy, tagging, skimming, selection (2)&lt;/h3&gt;
&lt;p&gt;I spent a good full day in 2018 to think about how I reacted on keywords, and came up with a taxonomy of keywords that fit my reading habits. I revised it twice over the past 3 years.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/cf-keyword.png&#34; alt=&#34;Tagging workflow&#34;&gt;&lt;/p&gt;
&lt;p&gt;I set Inoreader to first apply global deduplication to the entire newsriver.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/4-inoreader-filter.png&#34; alt=&#34;Inoreader deduplication&#34;&gt;&lt;/p&gt;
&lt;p&gt;There are indeed cases where the same article would appear multiple times, within the same feed and across distinct feeds.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/3-inoreader-filter-example-duplicate.png&#34; alt=&#34;Inoreader deduplication&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then, rules are triggered based on my interests in order to tag relevant content according to the following tags (some are omitted for NDA reasons).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/2-inoreader-tags.png&#34; alt=&#34;Inoreader tags&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here you can see some example rules that I created using regular expressions. Inoreader makes it extremely easy to do this.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/6-inoreader-rule-reporters.png&#34; alt=&#34;Inoreader rule&#34;&gt;&lt;/p&gt;
&lt;p&gt;The sources and tags are organized is such that I don&amp;rsquo;t have to think too much about what to read every time I check Inoreader. The top buckets will always appear at the top, and as I mark them as read, they&amp;rsquo;ll disappear from the current bucket, and from any other overlapping buckets below.&lt;/p&gt;
&lt;p&gt;When I find an interesting item, I tag it as &amp;ldquo;Noteworthy,&amp;rdquo; which triggers automatic archival and immediate sharing (e.g., on Twitter). I have private chats with co-workers where I share the same (or slightly different) content. I create one tag for each one of these cases so I can manage their workflows independently.&lt;/p&gt;
&lt;h3 id=&#34;live-sharing-with-minimum-friction-3&#34;&gt;Live Sharing With Minimum Friction (3)&lt;/h3&gt;
&lt;p&gt;I create so-called &amp;ldquo;export RSS feeds&amp;rdquo; for the folders and tags which content I want to post-process externally. This includes sharing with colleagues in a private chat, sending to a Telegram channel, publishing on Twitter (which I do, at 
&lt;a href=&#34;https://twitter.com/CyberFactsIT&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CyberFactsIT&lt;/a&gt;), or creating a web page like this one at 
&lt;a href=&#34;https://cyberfacts.it&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cyberfacts.it&lt;/a&gt;. Of course none of this involves any manual action. Instead, it&amp;rsquo;s al handled by Inoreader&amp;rsquo;s RSS export functionality, custom integrations and a GitHub Action to tweet from an RSS feed.&lt;/p&gt;
&lt;script src=&#34;https://gist.github.com/phretor/e51b826f77f046b3438e7a5cbb365386.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;When the content get shared via my social media channels, I receive notifications when people comment, re-share, or like, which gives me an indication of how good my choice was. Also, when I select an item about a completely new (but very important) topic, I setup auto-tagging of that topic, so that I get notified when something about that topic pops in the news again.&lt;/p&gt;
&lt;h3 id=&#34;reading-curation-annotation-summary-4&#34;&gt;Reading, curation, annotation, summary (4)&lt;/h3&gt;
&lt;p&gt;Every 1-2 days I go through my &amp;ldquo;Noteworthy&amp;rdquo; items and, also based on feedback from social media (if any), I choose the absolutely most important items and read through them in my browser. I have Zotero open all the time, so it only takes me the click of a button in Firefox on the Zotero Connector extension. Each weekly issue lives in a Zotero collection, with sorted sub-collections that mark any subsections I want to create.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/8-zotero-main.png&#34; alt=&#34;Zotero&#34;&gt;&lt;/p&gt;
&lt;p&gt;The item is snapshotted in HTML (with embedded elements, so the webpage is fully offline!), a new item is created into Zotero, pre-filled with most of the metadata (e.g., author, URL, date, title).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/9-zotero-item-details.png&#34; alt=&#34;Zotero item details&#34;&gt;&lt;/p&gt;
&lt;p&gt;While reading, I copy-paste 2-3 key sentences and add them into a child note of the item I just saved into Zotero. I also and start thinking about a one-liner to summarize the story, which may happen to be the same title chosen by the original reporter.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/10-zotero-writing-note.png&#34; alt=&#34;Zotero writing note&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;weekly-digest-sharing-5&#34;&gt;Weekly digest sharing (5)&lt;/h3&gt;
&lt;p&gt;Every week, I spend 30&amp;rsquo; to organize the selected content into 3+ groups: top most important items, also important, tools, and some other ad-hoc groups (e.g., vulnerabilities) as the content demands. I spend most of the 30&amp;rsquo; actually write an intro to the weekly issue, which goes in the top-level collection as a news item, with a child note holding the actual content.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/11-zotero-top-note-meta.png&#34; alt=&#34;Zotero top note meta&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/12-zotero-writing-top-note.png&#34; alt=&#34;Zotero writing top note&#34;&gt;&lt;/p&gt;
&lt;p&gt;The final step in Zotero is to export to a JSON file.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/13-zotero-export-dialog.png&#34; alt=&#34;Zotero export dialog&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/14-zotero-export.png&#34; alt=&#34;Zotero export&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/15-zotero-json-export.png&#34; alt=&#34;Zotero JSON&#34;&gt;&lt;/p&gt;
&lt;p&gt;From the weekly JSON file, I have automatic scripts that generate a Markdown file based on a Jinja template, containing an intro, table of content, summary, and list of grouped items.&lt;/p&gt;
&lt;p&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;That file is then converted into HTML (via 
&lt;a href=&#34;https://gohugo.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo&lt;/a&gt;) and summaries for Twitter and LinkedIn.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/scalable-handcurated-newsletter/i/16-issue-md.png&#34; alt=&#34;Conversion&#34;&gt;&lt;/p&gt;
&lt;p&gt;The resulting Markdown file or HTML can be shared to email subscribers via 
&lt;a href=&#34;https://buttondown.email&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Buttondown&lt;/a&gt;, which is what I do. It has an API, so I guess my next step is to create draft posts automatically, when generating the HTML file.&lt;/p&gt;
&lt;h2 id=&#34;whats-left&#34;&gt;What&amp;rsquo;s Left?&lt;/h2&gt;
&lt;p&gt;It&amp;rsquo;s a huge leap forward if compared to manually maintaining JSON, Markdown, or HTML files. Imagine a simple task like sorting items, or changing a title and update the table of contents, etc.&lt;/p&gt;
&lt;p&gt;However, there are a few things that will keep my weekends busy for a couple of hours:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;generate Twitter and LinkedIn post automatically and push draft via their APIs,&lt;/li&gt;
&lt;li&gt;generate a draft and push it to Buttondown via its API,&lt;/li&gt;
&lt;li&gt;trigger Hugo to re-generate the Markdown and HTML file every time the JSON is changed,&lt;/li&gt;
&lt;li&gt;&amp;hellip;and&amp;hellip;&lt;/li&gt;
&lt;li&gt;apply some machine-learning magic to automatically find interesting articles according to my selection habits of the past 2 years.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;That&amp;rsquo;s all folks!&lt;/p&gt;
&lt;p&gt;Thanks for reading this far. Hope you learned something new! And if you like to subscribe to my weekly digest or live feed, head over to the 
&lt;a href=&#34;/cyberfacts&#34;&gt;dedicated page&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;I don&amp;rsquo;t like this term, because more often then not, content is &amp;ldquo;pushed&amp;rdquo; to the mainstream media. Few people know about this fact and most people think that reporters have infinite time to consume all available resources.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Masked Emotions</title>
      <link>/post/masked-emotions/</link>
      <pubDate>Mon, 21 Dec 2020 17:36:57 +0100</pubDate>
      <guid>/post/masked-emotions/</guid>
      <description>&lt;p&gt;Despite this little beast known as 
&lt;a href=&#34;https://en.wikipedia.org/wiki/COVID-19_pandemic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;COVID-19 pandemic&lt;/a&gt; is about to turn 1 year old, many people still feel strange when wearing masks. While wearing a face mask we can&amp;rsquo;t speak properly and we can&amp;rsquo;t see others&amp;rsquo; mouth, so our experience of a conversation can change, especially if speaking is central in our lives (think of any public figure). Wearing a face mask impacts how we perceive others&amp;rsquo; emotions as well as our emotions (how we feel). Because our own understanding of our emotions can also influence such emotions in a continuous feedback loop, the effect can go beyond how we feel in that particular moment.&lt;/p&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#how-we-decode-emotions-through-facial-expressions&#34;&gt;How we Decode Emotions Through Facial Expressions&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#impact-on-our-ability-to-speak-and-understand&#34;&gt;Impact on our ability to speak and understand&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#my-little-funky-experiment&#34;&gt;My Little Funky Experiment&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#collecting-data-through-amazon-mechanical-turk&#34;&gt;Collecting data Through Amazon Mechanical Turk&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#the-importance-of-past-experience-people-we-dont-know&#34;&gt;The importance of past experience: People we don&amp;rsquo;t know&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#results-how-good-are-we-at-detecting-emotions-from-facial-expressions&#34;&gt;Results: How Good are we at Detecting Emotions from Facial Expressions?&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#results-how-fast-do-we-process-facial-expressions-with-and-without-masks&#34;&gt;Results: How Fast do We Process Facial Expressions With and Without Masks?&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#survival-adaptation-and-crime&#34;&gt;Survival, adaptation, and crime&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#social-impact-of-wearing-masks-and-change-in-emotions&#34;&gt;Social impact of wearing masks and change in emotions&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#a-face-mask-can-help-you-conceal-unauthentic-or-social-emotions&#34;&gt;A face mask can help you conceal unauthentic (or social) emotions&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#is-eye-only-emotion-communication-possible&#34;&gt;Is Eye-only Emotion Communication Possible?&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#how-to-better-communicate-when-wearing-masks&#34;&gt;How to better communicate when wearing masks?&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#image-credits&#34;&gt;Image Credits&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Given the central role of verbal and non-verbal communication in social interactions, if wearing a mask affects our abilities to communicate, our social interactions may be affected as well. Fortunately, there&amp;rsquo;s more than just facial features when judging someone&amp;rsquo;s emotions: Voice and body language can convey a good deal of information, which experienced public speakers known how to use to engage with the audience. The impact on social interactions of wearing a mask is hard to assess, however.&lt;/p&gt;
&lt;p&gt;I did a brief literature review and then decided to get my hands dirty and replicate some previous experiments on measuring our ability to assess others&amp;rsquo; emotions, using 45 participants that I recruited through the 
&lt;a href=&#34;https://www.mturk.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazon Mechanical Turk&lt;/a&gt; platform (for about $80), and 
&lt;a href=&#34;https://github.com/phretor/masked-emotions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;publicly release&lt;/a&gt; the collected data (540 data points obtained from 6 headshots of a mid-age man wearing a mask and 6 headshots of a mid-age woman without mask).&lt;/p&gt;
&lt;p&gt;The results are not completely in line with previous work: It seems that the batch of participants have performed better (10% better!) at assessing emotions &lt;em&gt;on masked faces&lt;/em&gt; than on non-masked faces. This difference may be explained by multiple factors explained below, but my best bet is that Amazon Mechanical Turk workers are mainly profit driven and opportunistic, so they may just randomly click to answer as fast as they could. However, only one participant has clicked the sentinel answer (a deliberately wrong answer I purposely inserted), so, at least they have read the options. Also, I wanted to put the participants under time pressure, giving them only 60 seconds to answer: Actually, our brain is way faster to assess emotions from facial expressions, to the point that it&amp;rsquo;s a subconscious decision.&lt;/p&gt;
&lt;p&gt;Overall, when looking at faces, participants took 18.58394 ± 10.18913 seconds on average to take the wrong decision, about 3 seconds slower if compared to when they take a correct decision. The presence of a mask only slightly reflected on timing (16.46097 ± 8.86441 with mask vs. 16.23333 ± 9.44054 without mask), but &lt;em&gt;correct decisions are taken about 3 seconds faster&lt;/em&gt;. This uncertainty has been found in previous work, too. Just for my own comparison (can&amp;rsquo;t possibly draw any conclusions here!), my 5 year old son never missed a shot when I showed him 6 masked faces and 6 non-masked faces, and took him 3.202 ± 1.469 seconds to assess emotions of non-masked faces vs. 5.364 ± 1.8593 when I showed masked faces. I know, I&amp;rsquo;m a proud father (very strong bias!) and it&amp;rsquo;s only one data point. Anyhow, despite the difference in the overall performance, both previous (strong and rigorous) research and my little funky experiment confirm that we tend to confuse sadness and disgust for other emotions (including neutral), which are the emotions that are mainly expressed by the muscles around our mouth. And very preliminary data (would be interesting to expand here) on young individuals show that they may be way better than we are at this task.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stay safe and be happy:&lt;/strong&gt; Wearing mask is essential to protect others—and ourselves, but primarily others! The price at stake here is much higher than a little confusion about others&amp;rsquo; emotion. Emotions are important, but life is more important! Don&amp;rsquo;t be dumb, don&amp;rsquo;t jump to conclusions (Pytlik, Soll, and Mehl, 2020)! Don&amp;rsquo;t be fooled by this article! Just wear a mask whenever you&amp;rsquo;re in public, especially if you&amp;rsquo;re closed to others but even no-one is around you, because social context has big impact on habits formation! And remember, it&amp;rsquo;s very hard to confusion happiness with any other emotions, even when wearing a mask. So, put a smile beneath your mask!&lt;/p&gt;
&lt;h2 id=&#34;how-we-decode-emotions-through-facial-expressions&#34;&gt;How we Decode Emotions Through Facial Expressions&lt;/h2&gt;
&lt;p&gt;Although a recent study has identified up to 27 types of emotions (Cowen and Keltner, 2017), emotions can be roughly categorized into 6 buckets (Ekman, 1970): anger, disgust, fearless, happiness, neutral, sadness. We as humans process faces “as a whole,” rather than processing individual features individually, and quickly (subconsciously) recognize what emotion the person we&amp;rsquo;re looking at is expressing—whether it is the true emotion or not, that&amp;rsquo;s another story.&lt;/p&gt;
&lt;p&gt;This happens even in cultures, such as Saudi Arabia, where veiling is the norm. Remember that certain people, like men and children, do not cover their faces, and women remove their veils at home or in female-only groups. So, humans of all cultures develop the same skills regardless of their public habits. But when we cannot see the whole face, such processing is forced to work with half the facial features (eye region).&lt;/p&gt;
&lt;p&gt;Fortunately, each facial feature alone, however, can communicate certain emotions particularly well. The mouth region, for instance, is good for expressing feelings of happiness, although the eye region is also essential (as both previous work and my little experiment have showed). Interestingly, looking at the eye and mouth allows a finer-grained emotion categorization, ranging from sadness and fear (eyes are important here) to disgust and happiness (mouth is the dominant feature).&lt;/p&gt;
&lt;h2 id=&#34;impact-on-our-ability-to-speak-and-understand&#34;&gt;Impact on our ability to speak and understand&lt;/h2&gt;
&lt;p&gt;Another important aspect is that emotions are influenced by—and can influence—our ability to communicate. If we feel we can&amp;rsquo;t properly communicate, we may feel upset or simply uncomfortable that we can’t have a proper conversation because our words sound muffled. But audible speech is only one mean of communication: According to a recent article appeared on 
&lt;a href=&#34;https://www.bbc.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BBC News&lt;/a&gt; (Carys Betteley, 2020), members of the deaf community and others with hearing problems struggle if face mask wearing becomes common and widespread. But, let&amp;rsquo;s not forget that millions of women around the world wear face veils every day, with few apparent problems (Ong, 2020). What can we learn from women who veil their faces about how to communicate effectively? I&amp;rsquo;m quoting a couple of interviews by BBC reporter (Ong, 2020):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Maria Ali, 34, a homemaker from Rawalpindi in Pakistan who wears a niqab, agrees. She says she has never had any problems communicating with other niqabi women, even ones who are strangers. “With their gestures and voice, you can understand what they mean.”&lt;/p&gt;
&lt;p&gt;Marjaan Ali, 23, from Thuwal, Saudi Arabia observes that her facial expressions differ when she has the niqab on. “I’m a bit more exaggerated,” says the recent graduate. “And I’ve noticed that over the years, I’ve learnt to use my eyebrows quite expressively.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Although we can&amp;rsquo;t certainly generalize from these two quotes, it seems that as long as you learn to use (hand) gestures, voice, and eyes to emphasize your feelings, you can still communicate properly. I couple of times I noticing no reactions while smiling at someone during a conversation, to implicitly communicate my agreement. Moments later I realized I was wearing a mask, so I tried to use hands to do a “thumbs up” sign, or use my eyes to emphasize the masked, nodding smile.&lt;/p&gt;
&lt;h2 id=&#34;my-little-funky-experiment&#34;&gt;My Little Funky Experiment&lt;/h2&gt;
&lt;p&gt;All researches conducted so far seem to confirm that masks prevent us from correctly assessing others&amp;rsquo; emotions. (Mike Rinck et al., 2020) recruited 91 participants, which showed altered emotion recognition for masked faces when recognizing disgust, fear, surprise, sadness, and happiness, but not anger or neutral expressions. Most of the confusion is on those emotions that share activation of the visible muscles in the upper half of the face. Participants frequently misinterpreted disgust as anger, and fear as surprise. Similarly, (Carbon, 2020) recruited 41 participant assessed the emotional expressions displayed by 12 different faces. Each face was randomly presented with the expressions of the 6 basic emotions while being fully visible or partly covered by a face mask. The researchers have found lower accuracy and lower confidence in recognizing emotions, indicating that emotional reading was strongly impaired by the mask. Specific confusion patterns occur in the case of misinterpreting disgusted faces as being angry, plus wrongly assessing many other emotions as neutral.&lt;/p&gt;
&lt;p&gt;After skimming through their results, I got intrigued and wanted to play around with some data as well. But reusing their data to draw the same pictures was not as exciting as repeating the experiment (on a smaller scale, of course). So I set off to work and prepared a survey.&lt;/p&gt;
&lt;h3 id=&#34;collecting-data-through-amazon-mechanical-turk&#34;&gt;Collecting data Through Amazon Mechanical Turk&lt;/h3&gt;
&lt;p&gt;This experiment does by no means substitute rigorous academic research, but after reading the work by (Mike Rinck et al., 2020) and (Carbon, 2020). I really became curious and wanted to create my own analysis. Of course the original survey by (Carbon, 2020) collected way more data than I did, and also made it 
&lt;a href=&#34;https://osf.io/3j7q5/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;available publicly&lt;/a&gt;. Last time I used Amazon Mechanical Turk was in 2014, so it was time for a quick refresh. It&amp;rsquo;s a powerful platform that allows anyone to quickly collect prepare experiments that require human intelligence and collect data. In about 14 hours I collected 540 data points and that costed me only $80. Of course it&amp;rsquo;s not the same as running in-lab experiments. If you&amp;rsquo;re using Amazing Mechanical Turk, remember to insert test questions (to discard results clearly coming from random, profit-driven clicks) and by choosing to assign tasks only to so-called Master Workers—which are workers with a positive historical record of approved high-quality tasks. There&amp;rsquo;s a 
&lt;a href=&#34;https://archive.is/in7QO&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;simple intro-level tutorial&lt;/a&gt; that guides you through all the technical steps required to setup and run a survey.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-facial-expressions-i-used-in-the-experiment-anger-disgust-fear-happyness-neutral-sad&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;/post/masked-emotions/featured_hu12146490337527537716.jpg&#34; data-caption=&#34;Facial expressions I used in the experiment: anger, disgust, fear, happyness, neutral, sad.&#34;&gt;


  &lt;img data-src=&#34;/post/masked-emotions/featured_hu12146490337527537716.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;2744&#34; height=&#34;1114&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Facial expressions I used in the experiment: anger, disgust, fear, happyness, neutral, sad.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;
&lt;a href=&#34;#figure-facial-expressions-i-used-in-the-experiment-anger-disgust-fear-happyness-neutral-sad&#34;&gt;Figure 1&lt;/a&gt; shows the pictures I used in the experiment for each of the 6 universal emotions: anger, disgust, fear, happiness, neutral, sad. I know, I combined two controlled variables in a single experiment (sex and presence of a mask), and that&amp;rsquo;s not a recommended experimental protocol. However, my time and resources were limited, and most of all I&amp;rsquo;m doing this just for fun and to play around with some data collection and analysis tools. I obtained the data from the 
&lt;a href=&#34;https://faces.mpdl.mpg.de&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FACES dataset&lt;/a&gt; (Ebner, Riediger, and Lindenberger, 2010) and I artificially applied a face mask on the pictures of the male model.&lt;/p&gt;
&lt;h3 id=&#34;the-importance-of-past-experience-people-we-dont-know&#34;&gt;The importance of past experience: People we don&amp;rsquo;t know&lt;/h3&gt;
&lt;p&gt;I decided to present images to each worker in random order, one at a time, not all at the same time. Why? Because I wanted to emulate the worst-case condition. Here&amp;rsquo;s the rationale: If I know a person I know their “normal” face or “angry” face very well. But if we look at the neutral face above (second from the right), are we 100% that couldn&amp;rsquo;t that be her angry or sad face? If I see the whole context then I have way more context to cast the correct decision—especially if I know there are 6 emotion types.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/masked-emotions/imgs/stranger.jpg&#34; alt=&#34;A stranger walking on a vessel.&#34;&gt;&lt;/p&gt;
&lt;p&gt;In other words, if I know a person, even when that person wears a mask, I can easily tell their emotions apart. But I was more interested in emulating the “random stranger” condition: Imagine you&amp;rsquo;re walking on the street and a person you&amp;rsquo;ve never seen before walks toward you with a sad-looking face—or angry-looking face, who knows! How good are you at telling those two very different emotions apart? Anger and sadness are quite different emotions, but because of the mask and the complete lack of past experience you simply can&amp;rsquo;t guess. It&amp;rsquo;s the worst-case condition and I wanted to emulate exactly that.&lt;/p&gt;
&lt;p&gt;Following the same line of thought, I decided to impose a 60s time constrain for workers to complete each task (1 face). Why is timing important? Because when we glance at someone&amp;rsquo;s face we make unconscious decisions and those are quite fast. (Carbon, 2020) gave the participants “unlimited” time to complete the task and collected a conscious assessment of their “confidence” in their decision. I decided to focus on a fast task, because at the end of the day, that&amp;rsquo;s how our brain works when we see someone.&lt;/p&gt;
&lt;h3 id=&#34;results-how-good-are-we-at-detecting-emotions-from-facial-expressions&#34;&gt;Results: How Good are we at Detecting Emotions from Facial Expressions?&lt;/h3&gt;
&lt;p&gt;As the following figure shows, I obtained mixed results, sometimes opposite from what previous (and more thorough) work has found. In most of the times, as the green diagonal shows, the emotions where correctly classified, with more confusion in the masked case (bottom row). In particular, we notice that happiness is a “strong” emotion, in the sense that it almost never got misclassified (only 4 cases out of 270 in the masked condition, and zero cases in the unmasked condition). So, smile whenever you can! Sadness and disgust are particularly challenging emotions, especially in the masked condition, and neutral got misclassified 10% of the times for other emotions—mainly anger—in the unmasked condition. Surprisingly, neutral emotions appear more neutral in the masked condition. Does masks make us all appear more serious? Maybe!&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-confusion-matrix-showing-the-number-of-correct-detections-for-each-combination-of-real-detected-emotions-the-greener-the-better&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;/post/masked-emotions/imgs/confusion_hu12473860164509649863.jpg&#34; data-caption=&#34;Confusion matrix showing the number of correct detections for each combination of real-detected emotions. The greener, the better.&#34;&gt;


  &lt;img data-src=&#34;/post/masked-emotions/imgs/confusion_hu12473860164509649863.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;3200&#34; height=&#34;2400&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Confusion matrix showing the number of correct detections for each combination of real-detected emotions. The greener, the better.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The overall performance for correctly detecting facial emotions in faces without masks was 70.00% (while 89.5% in (Carbon, 2020)). Presenting a different face (to reduce the effects of learning, or simply cheating) resulted in a 79.25%. Yes, the workers—assuming they didn&amp;rsquo;t cheat (and that&amp;rsquo;s a big assumption)—performed better when presented with masked faces. This is the opposite of what (Carbon, 2020) found, but I&amp;rsquo;m skeptical of my own data. There may be various explanations and the only way to give a clear answer is to repeat the experiments several times, but I simply don&amp;rsquo;t have enough time to dig further, so I&amp;rsquo;m just providing some wild guesses. Maybe someone will do some followup work.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Small sample and multiple controlled variables:&lt;/strong&gt; to keep the investment below $100, I had to reduce the number of stimuli to 1 mid-age man for masked faces, 1 mid-age woman for non-masked faces, while the original study has employed all variants (male vs. female w/ and w/o mask): it&amp;rsquo;s an experimental mistake to combine multiple variables, because now we don&amp;rsquo;t know whether the reason is that the non-masked woman model was less expressive or, vice-versa, the masked man had very expressive eyes;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Time:&lt;/strong&gt; the time pressure may have forced the workers to simply cast a random choice or the workers may have taken the tasks in a very opportunistic way. However, if we pivot the data, we see that, overall, they make sense (see the timing analysis below).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;We&amp;rsquo;ve grown accustomed to this!&lt;/strong&gt; Hey, let&amp;rsquo;s look at the bright side of it: the 45 participants may have gotten better at assessing emotions by looking at the eyes only. Not really sure this is the case, but I gave it a thought for a moment.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lots of open questions and little time to continue this research. But it was fun to learn how to deploy this type of studies from scratch. Next time I&amp;rsquo;ll certainly think twice and/or invest more resources to conduct wider studies. Let&amp;rsquo;s move onto the timing analysis now.&lt;/p&gt;
&lt;h3 id=&#34;results-how-fast-do-we-process-facial-expressions-with-and-without-masks&#34;&gt;Results: How Fast do We Process Facial Expressions With and Without Masks?&lt;/h3&gt;
&lt;p&gt;My 5 year old son never misclassified a facial expression when I showed him 6 masked faces and 6 non-masked faces, and took him 3.202 ± 1.469 seconds to assess emotions of non-masked faces vs. 5.364 ± 1.8593 when I showed masked faces. This initial home experiment got me into thinking I should look at the time spent by the workers to complete their task. Big warning: this time includes the time required to click on the next page, wait for the page to load, and finally click on the “submit” button. So, let&amp;rsquo;s look at it but take it with a grain of salt.&lt;/p&gt;
&lt;p&gt;As we can see from 
&lt;a href=&#34;#figure-overall-time-to-detect-facial-emotions-in-case-of-correct-blue-and-incorrect-false-detections&#34;&gt;Figure 3&lt;/a&gt;, regardless of whether one&amp;rsquo;s wearing a mask, correct detections overall take about 3 second less than incorrect ones (15.60794 ± 8.65164 versus 18.58394 ± 10.18913). Also, we can see that participants who didn&amp;rsquo;t detect the correct emotion from facial expressions spent a highly variable time staring at the picture, while timing for correct detections are more densely distributed around mean values.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-overall-time-to-detect-facial-emotions-in-case-of-correct-blue-and-incorrect-false-detections&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;/post/masked-emotions/imgs/timing_hu16393481769333423570.jpeg&#34; data-caption=&#34;Overall time to detect facial emotions in case of correct (blue) and incorrect (false) detections.&#34;&gt;


  &lt;img data-src=&#34;/post/masked-emotions/imgs/timing_hu16393481769333423570.jpeg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1000&#34; height=&#34;400&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Overall time to detect facial emotions in case of correct (blue) and incorrect (false) detections.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Looking at the breakdown in 
&lt;a href=&#34;#figure-breakdown-on-real-emotions-displayed-on-the-stimuli&#34;&gt;Figure 4&lt;/a&gt; we see that the mask condition (bottom row) almost always means the subject will spend some more time to look at the picture and still make the incorrect guess. Some facial expressions seem to create more confusion than others: look at fear or neutral for example. When presented with unmasked facial expressions (upper row), the subject will spend roughly the same amount of time, regardless of the outcome (correct vs. incorrect), while in the bottom row we see more diverse cases.&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-breakdown-on-real-emotions-displayed-on-the-stimuli&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;/post/masked-emotions/imgs/timing-detailed_hu5133896203654422755.jpg&#34; data-caption=&#34;Breakdown on real emotions displayed on the stimuli.&#34;&gt;


  &lt;img data-src=&#34;/post/masked-emotions/imgs/timing-detailed_hu5133896203654422755.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;3200&#34; height=&#34;2400&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Breakdown on real emotions displayed on the stimuli.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;survival-adaptation-and-crime&#34;&gt;Survival, adaptation, and crime&lt;/h2&gt;
&lt;p&gt;Since our earliest days, human beings have been incredibly attuned to reading the facial expressions of others. This ability likely conferred upon us an evolutionary advantage, Charles Darwin (Darwin, 1872)Learning how to read emotions from a face could aid social interaction, reduce misunderstandings and help a group function efficiently and harmoniously for the greater good, said (Ong, 2020).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/masked-emotions/imgs/malice.jpg&#34; alt=&#34;Dark scenery with unrecognizable person.&#34;&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://pure.hud.ac.uk/en/persons/eilidh-garvey&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Eilidh Noyes&lt;/a&gt;, lecturer in cognitive psychology at the 
&lt;a href=&#34;https://hud.ac.uk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Huddersfield&lt;/a&gt; in northern England said that&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When you see a face you do two things at once. You try to work out the identity: Do I know them? How do I know them? And you try to read their emotions. [&amp;hellip;] Emotion recognition is important from an evolutionary perspective as it helps us gauge threat and can also facilitate positive social interactions. That’s true of both people we know well and those we have never met.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Similarly, 
&lt;a href=&#34;https://www.tcd.ie/research/profiles/?profile=iroberts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ian H. Robertson&lt;/a&gt;, professor of psychology at 
&lt;a href=&#34;https://www.tcd.ie&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trinity College Dublin&lt;/a&gt; said that&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For survival reasons, you need to know what someone’s intentions are when you meet them. Not being able to do that easily will naturally make people more cautious and defensive, which in some cases could, unfortunately, lead to violent confrontations.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Source: (CORDIS, 2020).&lt;/p&gt;
&lt;p&gt;Understanding others&amp;rsquo; emotion has been a matter of survival, but not as much as in ancient times. So there&amp;rsquo;s no doubt it&amp;rsquo;s important to assess emotions correctly, but only in certain, very extreme situations, when normally there are other clues available: A loud screaming voice to signal emergency would be understood as fear no matter what. So, overall, I don&amp;rsquo;t agree with this line of thoughts and I consider it very borderline if not biased.&lt;/p&gt;
&lt;p&gt;I do agree with the fact that with mask becoming the norm there is the potential for exploitation by those with criminal intentions.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The main problem that people wearing masks throws up is the sheer volume of people suddenly covering their faces&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;said 
&lt;a href=&#34;https://www.kingston.ac.uk/staff/profile/dr-francis-dodsworth-241/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Francis Dodsworth&lt;/a&gt;, senior lecturer in criminology at 
&lt;a href=&#34;https://www.kingston.ac.uk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kingston University London&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It could create opportunities for people who want to cover their face for nefarious reasons. They could potentially now do so without raising suspicion.&lt;/p&gt;
&lt;p&gt;Concealing faces will also have widespread implications for crime and security. A lot of witnessing is already problematic. Even when a group of people witness the same crime, one person will see someone with a mustache and a hat, while another will see someone with a beard and sunglasses.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Source: (CORDIS, 2020)&lt;/p&gt;
&lt;h2 id=&#34;social-impact-of-wearing-masks-and-change-in-emotions&#34;&gt;Social impact of wearing masks and change in emotions&lt;/h2&gt;
&lt;p&gt;I still feel a little strange when wearing a mask, but my rational part is now in full control of those mixed emotion, and I simply forget I&amp;rsquo;m wearing a mask at times. In May, 
&lt;a href=&#34;https://www.reading.ac.uk/pcls/staff/katie-gray&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kate Gray&lt;/a&gt;, who researches emotion processing at the 
&lt;a href=&#34;https://www.reading.ac.uk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Reading&lt;/a&gt; in the UK, mentioned that adapting to a faceless society will be a smooth process: &lt;em&gt;“[&amp;hellip;] we’ll quite quickly get used to picking up social and emotional cues from voice cues or body language.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/masked-emotions/imgs/masks.jpg&#34; alt=&#34;Three people wearing face mask.&#34;&gt;&lt;/p&gt;
&lt;p&gt;I remember that the first time I saw my father wearing a mask it felt very strange. And when I started wearing a mask and people around me wouldn&amp;rsquo;t, I felt even stranger—like I was over-reacting. I bet I wasn&amp;rsquo;t the only one feeling strange, and an early research appeared earlier this year scientifically confirmed that the simple exposure to social groups of mask wearers greatly reduces that strange feeling (Carbon, 2020). The researchers have asked 86 participants to assess how strange they felt when wearing a mask (i.e., simple surgery mask, FFP2 mask, and loop scarfs) among other mask wearers, in groups of varying size. The larger the social group, the less strange each member feels about themselves.&lt;/p&gt;
&lt;p&gt;So, one part of the impact on emotion seems to be that wearing masks makes us feel a little different, triggers different or slightly different emotions. When we wear a mask we’re left only with the eyes, and that can make it difficult for people to make these judgments. According to 
&lt;a href=&#34;https://www.brandeis.edu/facultyguide/person.html?emplid=2eb6be94b388be4b500e54ef726277fd747f02bb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Leslie Zebrowitz&lt;/a&gt;, psychology professor who studies facial perception at 
&lt;a href=&#34;https://www.brandeis.edu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brandeis University&lt;/a&gt;, told that &lt;em&gt;“We feel more comfortable when we feel that we’re able to assess what someone is like”&lt;/em&gt; (CORDIS, 2020).&lt;/p&gt;
&lt;h2 id=&#34;a-face-mask-can-help-you-conceal-unauthentic-or-social-emotions&#34;&gt;A face mask can help you conceal unauthentic (or social) emotions&lt;/h2&gt;
&lt;p&gt;Here&amp;rsquo;s another line of thoughts I tend to agree with, probably because I&amp;rsquo;m introvert. We—introvers—won&amp;rsquo;t be showing our true emotions anyhow, with or without mask, so why bother? We don’t have to be happy to smile, and we don’t always smile when we’re happy. This can vary greatly across cultures. In the United States, smiling is part of the etiquette, while a 
&lt;a href=&#34;https://archive.is/wip/vm2kd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Russian proverb translates as &lt;em&gt;“smiling with no reason is a sign of stupidity.”&lt;/em&gt;&lt;/a&gt; In Japan, emotions are stifled in public, there’s a greater emphasis on smiling with the eyes, so Japanese people may be able to convey—and read—their emotions through facial expressions more effectively.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/masked-emotions/imgs/lonely.jpg&#34; alt=&#34;Person in a hoodie.&#34;&gt;&lt;/p&gt;
&lt;p&gt;Tara Well, Associate Professor of Psychology at Barnard College of Columbia University, recently wrote a short thought piece about the social smile (Tara Well, 2020). She wrote that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The social smile is activated in the mouth muscles only and, therefore, easily covered up by a face mask. But a genuine smile, known as the Duchenne smile, named after the French anatomist who discovered it, involves both the mouth and the eyes. Interestingly, the facial muscle engaged by a genuine smile, called the orbicularis oculi, can’t be activated on command. You can see an authentic smile in the crinkles around the eyes.&lt;/p&gt;
&lt;p&gt;According to this, the face mask only hides the fake smiles, not the authentic ones. Think about it: when you&amp;rsquo;re truly smiling (close to laughing), extending your mouth isn&amp;rsquo;t enough. On the other hand, when you make a forced smile, it&amp;rsquo;s istantaneous, and it only involves the muscles around your mouth. Prof. T. Well continues explaining how, for some personality types, wearing a mask may even have a beneficial impact in their emotional space:&lt;/p&gt;
&lt;p&gt;Those suffering from social anxiety may welcome wearing face masks precisely because &lt;em&gt;they prefer to veil their emotional state from the outside world as much as possible&lt;/em&gt;. [&amp;hellip;] Others appreciate the freedom from the obligation to put others at ease with a warm, friendly smile. By wearing a face mask, you don’t have to smile if you don’t feel like it.&lt;/p&gt;
&lt;p&gt;We learn when to show and hide our genuine emotions from early face-to-face exchanges. Parents instinctively want to shield their children from negative social experiences. So they reward emotional displays that will encourage and facilitate acceptance from others. Children learn to behave in specific ways to receive social approval. Part of this process is developing a social smile to hide unacceptable emotions. (see book on negative factors of this).&lt;/p&gt;
&lt;p&gt;The social smile is often activated automatically. We may not be fully aware of it. We might smile reflexively to put the brakes on showing too much negative emotion in public. We may maintain a calm, relaxed smile to prevent fear from upwelling and getting the best of us. We can also intentionally use the social smile to pepper our communication—like smiling, assuringly at someone who appears suspicious of us.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I&amp;rsquo;m among those who “suffer” when the social “norm” ask us to smile or simply for an emotion, so I like this viewpoint. An Asian friend a few years ago told me some Asian people cover their faces with a mask or scarf loop not only during flu season, but simply beacuse they don&amp;rsquo;t always want to show their mouth area or full face in public. Whether or not that&amp;rsquo;s a bias in his social circle, I sometimes feel the same.&lt;/p&gt;
&lt;h2 id=&#34;is-eye-only-emotion-communication-possible&#34;&gt;Is Eye-only Emotion Communication Possible?&lt;/h2&gt;
&lt;p&gt;Shakespeare said that the eyes were the windows to the soul. Indeed, eyes alone can provide a great deal of information. 
&lt;a href=&#34;https://www.aber.ac.uk/en/psychology/staff-profiles/listing/profile/nih12/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nigel Holt&lt;/a&gt;, Professor of Psychology at 
&lt;a href=&#34;https://www.aber.ac.uk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aberystwyth University&lt;/a&gt; recently wrote (Holt, 2020) that “we are wired to extract information from the eyes—information that can help us assess the emotions of those around us and so allow us to engage more effectively with them.” Eyes alone can be quite effective, as (Lee and Anderson, 2017) showed. They showed volunteers images of eyes expressing different emotions (sadness, disgust, anger, joy, surprise, fear) and found out that the participants were able to correctly guess the mental states to the “eye expression”. From this research it emerged that different aspects of the eyes (such as how open they are or how sloped the brow is) give information about different mental states.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/masked-emotions/imgs/eyes.jpg&#34; alt=&#34;Eyes&#34;&gt;&lt;/p&gt;
&lt;p&gt;Eye contact is also essential in social interactions as well as in the emotions that gazing at eye level can trigger. (Guastella, Mitchell, and Dadds, 2008) showed images of faces to people who are given oxytocin, and found out that they spend more time looking at the eyes than those given a placebo. Since oxytocin is a factor in social interactions, this finding suggests the eyes are very important in how we understand our engagement and interaction with those around us. Indeed, people with high levels of oxytocin appear to seek out the eyes to help them better engage socially with others.&lt;/p&gt;
&lt;p&gt;From a perception viewpoint, we know that we are exceptionally sensitive to very tiny changes in direction of gaze, because the center of our retina is densely populated with light receptors. But a recent study showed that this goes beyond just sensitivity and perception. When we try to assess which direction someone is looking in, it significantly activates our amygdala, a part of the brain associated with emotion. So there seems to be a link between emotion and eyes at a neurological level (Kawashima et al., 1999).&lt;/p&gt;
&lt;p&gt;When eyes are the only feature available the role of the context could be crucial, but there&amp;rsquo;s no strong evidence about this.(Kret and de Gelder, 2012) tested whether emotions can be recognized when just the eyes are visible and whether this recognition is affected by context cues (e.g., various Islamic headdresses vs. a cap or a scarf). The results are that fear is still well recognized from a briefly flashed (100 ms) image of a women wearing a burqa with less than 20% transparency of the eye region.&lt;/p&gt;
&lt;p&gt;Last, let me bring up a different viewpoint on eye-only emotion communication. It&amp;rsquo;s somewhat common belief that if someone is “looking up and to the right” when they are talking then they may be lying. (Wiseman et al., 2012) filmed a group of people telling true and false stories, and then asked another group to try to spot the lies by looking at the speakers’ eyes. This experiment found no evidence for a link between lying and eye movements at all. So, eye-only emotion communication is possible, but not as reliable as one may think.&lt;/p&gt;
&lt;h2 id=&#34;how-to-better-communicate-when-wearing-masks&#34;&gt;How to better communicate when wearing masks?&lt;/h2&gt;
&lt;p&gt;Some 
&lt;a href=&#34;https://www.boredpanda.com/doctor-portraits-on-protective-gear/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;healthcare workers on the frontline have attached smiley-faced pictures of themselves&lt;/a&gt; onto their medical gowns, trying to ease patient anxiety (Ong, 2020). That&amp;rsquo;s one practical and simple way to show your best emotion (happyness) when people around you need that. Especially when we can&amp;rsquo;t talk, I don&amp;rsquo;t see any better way than that.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/masked-emotions/imgs/healthcare-workers.jpg&#34; alt=&#34;Healthcare workers with a smiley-faced picture.&#34;&gt;&lt;/p&gt;
&lt;p&gt;But when we can talk and move freely, it&amp;rsquo;s a whole different story. Psychologist Al Zayer suggests that, when wearing a mask, we should strive to over-communicate, use more words than we normally would, and ask more questions, to make sure we&amp;rsquo;re picking up on the other person’s emotions. Isn&amp;rsquo;t that what professional radio speakers or podcast creators do? They can convey very deep emotions and many shades of emotions by using their voice only. Normally, facial expressions form part of a coordinated set of features—including hand gestures, body language, words, pitch and tone, and even face colour (Benitez-Quiroz, Srinivasan, and Martinez, 2018). All of these features act together to convey message, intent, and emotions. And the best part is that, for some people, this is all natural. No training needed!&lt;/p&gt;
&lt;p&gt;I want to close with a fun fact. There are 
&lt;a href=&#34;https://archive.is/wip/SAyaJ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;prototypes of a voice-activated mask, currently in the crowdfunding stages&lt;/a&gt; (Georgia Coggan, 2020). The mask uses LED lights to display emotion or words. The LED lights can mimic the mouth movements, with simple commands like “popping the lips” to display simple words, emojis or smiles.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/masked-emotions/imgs/led-mask.jpg&#34; alt=&#34;LED mask&#34;&gt;&lt;/p&gt;
&lt;p&gt;The artificial mouth tracks the mouth of the user, emulating the physical action of the lips. It&amp;rsquo;s a matter of time and someone will make the flexible OLED version of that, showing a full, high-resolution picture of your mouth area recorded in real time from a micro-camera with IR illuminators positioned inside the mask.&lt;/p&gt;
&lt;p&gt;For now, I&amp;rsquo;m sticking to the old-school approach.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/masked-emotions/imgs/old-school.jpeg&#34; alt=&#34;Old school approach&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Baron-Cohen, Simon, Sally Wheelwright, Jacqueline Hill, Yogini Raste, and Ian Plumb. “The ‘Reading the Mind in the Eyes’ Test Revised Version: A Study with Normal Adults, and Adults with Asperger Syndrome or High-Functioning Autism.” The Journal of Child Psychology and Psychiatry and Allied Disciplines 42, no. 2 (February 2001): 241–51. 
&lt;a href=&#34;https://doi.org/10/fdwnm3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/fdwnm3&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Benitez-Quiroz, Carlos F., Ramprakash Srinivasan, and Aleix M. Martinez. “Facial Color Is an Efficient Mechanism to Visually Transmit Emotion.” Proceedings of the National Academy of Sciences 115, no. 14 (April 3, 2018): 3581–86. 
&lt;a href=&#34;https://doi.org/10/gdb3m5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/gdb3m5&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Carbon, Claus-Christian. “The Psychology of Wearing Face Masks in Times of the COVID-19 Pandemic.” SSRN Scholarly Paper. Rochester, NY: Social Science Research Network, April 24, 2020. 
&lt;a href=&#34;https://doi.org/10.2139/ssrn.3584834&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.2139/ssrn.3584834&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Carbon, Claus-Christian. “Wearing Face Masks Strongly Confuses Counterparts in Reading Emotions.” Frontiers in Psychology 11 (September 25, 2020). 
&lt;a href=&#34;https://doi.org/10/ghp92r&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/ghp92r&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Carys Betteley. “Coronavirus: Mask Wearing ‘risks Isolating’ Deaf People.” BBC News, May 14, 2020, sec. Wales. 
&lt;a href=&#34;https://www.bbc.com/news/uk-wales-52659083&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.bbc.com/news/uk-wales-52659083&lt;/a&gt;. 
&lt;a href=&#34;https://archive.is/L3TKW&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Archived copy&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;CORDIS. “Are Masks the New Face of Our Society? Science and the Changing Landscape of Human Expression | News | CORDIS | European Commission.” News. Trending Science. Community Research and Development Information Service (CORDIS), May 28, 2020. 
&lt;a href=&#34;https://cordis.europa.eu/article/id/418273-human-expression&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://cordis.europa.eu/article/id/418273-human-expression&lt;/a&gt; (
&lt;a href=&#34;https://archive.is/wip/SCjDP&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Archived copy&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Cowen, Alan S., and Dacher Keltner. “Self-Report Captures 27 Distinct Categories of Emotion Bridged by Continuous Gradients.” Proceedings of the National Academy of Sciences 114, no. 38 (September 19, 2017): E7900–7909. 
&lt;a href=&#34;https://doi.org/10/gfhzd2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/gfhzd2&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Darwin, Charles. The Expression of the Emotions in Man and Animals. J. Murray, 1872.&lt;/li&gt;
&lt;li&gt;Ebner, Natalie C., Michaela Riediger, and Ulman Lindenberger. “FACES—A Database of Facial Expressions in Young, Middle-Aged, and Older Women and Men: Development and Validation.” Behavior Research Methods 42, no. 1 (February 1, 2010): 351–62. 
&lt;a href=&#34;https://doi.org/10/ftbs4j&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/ftbs4j&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Ekman, Paul. “Universal Facial Expressions of Emotion.” California Mental Health Research Digest 8, no. 4 (1970): 151–58.&lt;/li&gt;
&lt;li&gt;Georgia Coggan. “Incredible New Face Mask Displays Your Emotions.” Creative Bloq, September 2020. 
&lt;a href=&#34;https://www.creativebloq.com/news/led-face-mask&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.creativebloq.com/news/led-face-mask&lt;/a&gt;. 
&lt;a href=&#34;https://archive.is/wip/tIVaO&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Archived copy&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Gorvett, Zaria. “There Are 19 Types of Smile but Only Six Are for Happiness,” April 10, 2017. 
&lt;a href=&#34;https://www.bbc.com/future/article/20170407-why-all-smiles-are-not-the-same&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.bbc.com/future/article/20170407-why-all-smiles-are-not-the-same&lt;/a&gt;. 
&lt;a href=&#34;https://archive.is/wip/vOfcc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Archived copy&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Guastella, Adam J., Philip B. Mitchell, and Mark R. Dadds. “Oxytocin Increases Gaze to the Eye Region of Human Faces.” Biological Psychiatry, Schizophrenia: From Genetics to Treatment, 63, no. 1 (January 1, 2008): 3–5. 
&lt;a href=&#34;https://doi.org/10/c8mvmg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/c8mvmg&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Holt, Nigel. “Face Masks: Why Your Eyes Might Be Saying More than You Realise.” The Conversation, September 1, 2020. 
&lt;a href=&#34;http://theconversation.com/face-masks-why-your-eyes-might-be-saying-more-than-you-realise-145076.[Archived&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://theconversation.com/face-masks-why-your-eyes-might-be-saying-more-than-you-realise-145076.[Archived&lt;/a&gt; copy](
&lt;a href=&#34;https://archive.is/wip/A1yfF%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://archive.is/wip/A1yfF)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Kawashima, Ryuta, Motoaki Sugiura, Takashi Kato, Akinori Nakamura, Kentaro Hatano, Kengo Ito, Hiroshi Fukuda, Shozo Kojima, and Katsuki Nakamura. “The Human Amygdala Plays an Important Role in Gaze Monitoring: A PET Study.” Brain 122, no. 4 (April 1, 1999): 779–83. 
&lt;a href=&#34;https://doi.org/10/dsqnk6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/dsqnk6&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Kret, Mariska Esther, and Beatrice de Gelder. “Islamic Headdress Influences How Emotion Is Recognized from the Eyes.” Frontiers in Psychology 3 (2012): 110. 
&lt;a href=&#34;https://doi.org/10/ghp92q&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/ghp92q&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Lee, Daniel H., and Adam K. Anderson. “Reading What the Mind Thinks From How the Eye Sees.” Psychological Science 28, no. 4 (April 2017): 494–503. 
&lt;a href=&#34;https://doi.org/10/f942wj&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/f942wj&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Mike Rinck, Maximilian Primbs, Iris Verpaalen, and Gijs Bijlstra. “The Effect of Face Masks on Facial Emotion Recognition.” Behavioural Science Institute, 2020. 
&lt;a href=&#34;https://www.ru.nl/bsi/covid-19-bsi-studies/effect-face-masks-facial-emotion-recognition/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.ru.nl/bsi/covid-19-bsi-studies/effect-face-masks-facial-emotion-recognition/&lt;/a&gt;. 
&lt;a href=&#34;https://archive.is/wip/D9xhK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Archived copy&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Ong, Sandy. “How Face Masks Affect Our Communication.” BBC Future, June 8, 2020. 
&lt;a href=&#34;https://www.bbc.com/future/article/20200609-how-face-masks-affect-our-communication&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.bbc.com/future/article/20200609-how-face-masks-affect-our-communication&lt;/a&gt;. 
&lt;a href=&#34;https://archive.is/wip/S3wvO&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Archived copy&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Pytlik, Nico, Daniel Soll, and Stephanie Mehl. “Thinking Preferences and Conspiracy Belief: Intuitive Thinking and the Jumping to Conclusions-Bias as a Basis for the Belief in Conspiracy Theories.” Frontiers in Psychiatry 11 (2020). 
&lt;a href=&#34;https://doi.org/10/ghpdjv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/ghpdjv&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Tara Well. “Do Face Masks Really Conceal Emotions?” Medium, August 4, 2020. 
&lt;a href=&#34;https://medium.com/@tarawell/do-face-masks-really-conceal-emotions-98a7bfe3af66&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/@tarawell/do-face-masks-really-conceal-emotions-98a7bfe3af66&lt;/a&gt;. 
&lt;a href=&#34;https://archive.is/wip/q180I&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Archived copy&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Wegrzyn, Martin, Maria Vogt, Berna Kireclioglu, Julia Schneider, and Johanna Kissler. “Mapping the Emotional Face. How Individual Face Parts Contribute to Successful Emotion Recognition.” PLoS ONE 12, no. 5 (May 11, 2017). 
&lt;a href=&#34;https://doi.org/10/f9699b&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/f9699b&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Wiseman, Richard, Caroline Watt, Leanne ten Brinke, Stephen Porter, Sara-Louise Couper, and Calum Rankin. “The Eyes Don’t Have It: Lie Detection and Neuro-Linguistic Programming.” PLOS ONE 7, no. 7 (July 11, 2012): e40259. 
&lt;a href=&#34;https://doi.org/10/kxh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10/kxh&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;image-credits&#34;&gt;Image Credits&lt;/h2&gt;
&lt;p&gt;In order of appearance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Photo of person walking on a boat by 
&lt;a href=&#34;https://unsplash.com/@kaziiparkour?utm_source=unsplash&amp;amp;amp;utm_medium=referral&amp;amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zakaria Zayane&lt;/a&gt; on 
&lt;a href=&#34;https://unsplash.com/s/photos/stranger-look?utm_source=unsplash&amp;amp;amp;utm_medium=referral&amp;amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsplash&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Photo showing dark scenery with an unrecognizable person by 
&lt;a href=&#34;https://unsplash.com/@sm83?utm_source=unsplash&amp;amp;amp;utm_medium=referral&amp;amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Peter Scherbatykh&lt;/a&gt; on 
&lt;a href=&#34;https://unsplash.com/s/photos/crime?utm_source=unsplash&amp;amp;amp;utm_medium=referral&amp;amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsplash&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Photo of a person in a hoodie by 
&lt;a href=&#34;https://unsplash.com/@patryksobczak?utm_source=unsplash&amp;amp;amp;utm_medium=referral&amp;amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Patryk Sobczak&lt;/a&gt; on 
&lt;a href=&#34;https://unsplash.com/s/photos/lonely?utm_source=unsplash&amp;amp;amp;utm_medium=referral&amp;amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsplash&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Photo of eyes closeup by 
&lt;a href=&#34;https://unsplash.com/@kj2018?utm_source=unsplash&amp;amp;amp;utm_medium=referral&amp;amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kat J&lt;/a&gt; on 
&lt;a href=&#34;https://unsplash.com/s/photos/eyes-only?utm_source=unsplash&amp;amp;amp;utm_medium=referral&amp;amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsplash&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Photo of healthcare workers by 
&lt;a href=&#34;https://www.instagram.com/derekdevault/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;derekdevault&lt;/a&gt; (via 
&lt;a href=&#34;https://www.boredpanda.com/doctor-portraits-on-protective-gear/?utm_source=google&amp;amp;utm_medium=organic&amp;amp;utm_campaign=organic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;boredpanda.com&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Photo of JabberMask by 
&lt;a href=&#34;https://twitter.com/TylerGlaiel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tyler Glaiel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Reading Aloud</title>
      <link>/post/reading-aloud/</link>
      <pubDate>Mon, 14 Dec 2020 17:18:55 +0100</pubDate>
      <guid>/post/reading-aloud/</guid>
      <description>&lt;p&gt;Reading long texts has always been a daunting task to me. A rocky mountain I seldom find myself brave enough to start climbing (unless forced to). I&amp;rsquo;ve never had good reading habits, except for a few, very intriguing novels with a powerful storyline, which I could actually read quite fast. But most of the readings I wish I could get done quickly are damn hard. In the era of 
&lt;a href=&#34;https://mashable.com/shopping/march-23-book-summary-apps/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;book-summarizing services&lt;/a&gt; like 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Blinkist&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Blinkist&lt;/a&gt;, 
&lt;a href=&#34;https://www.cbsnews.com/news/the-explosion-in-audio-books/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;audiobooks&lt;/a&gt;, and &amp;ldquo;CEO reading guides,&amp;rdquo; where people invest time and money to compress time and read more, my limited reading abilities are an actual obstacle to my knowledge development. How did I change that? I don&amp;rsquo;t know if I did, but here is what I found by experimenting on myself.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;In short:&lt;/strong&gt; I got significantly better a reading when I started reading aloud, record my voice, and share partial audio files with friends, who told me they ejoyed listening to my recordings, and that helped them stay motivated. The power of social incentives!&lt;/p&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#the-joy-pain-of-reading&#34;&gt;The &lt;del&gt;Joy&lt;/del&gt; Pain of Reading&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#could-i-motivate-myself-to-read-more&#34;&gt;Could I Motivate Myself to Read More?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#intrinsic-vs-extrinsic-motivation&#34;&gt;Intrinsic vs. Extrinsic Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#the-microphone-that-brought-in-new-incentives&#34;&gt;The Microphone that Brought in New Incentives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#read-for-someone-else-your-age&#34;&gt;Read for Someone Else (Your Age)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#the-turning-point-helping-and-motivating-others&#34;&gt;The Turning Point: Helping and Motivating Others&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#seeing-progress&#34;&gt;Seeing Progress&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#the-tedx-talk-that-made-me-write-this&#34;&gt;The TEDx Talk That Made Me Write This&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-joy-pain-of-reading&#34;&gt;The &lt;del&gt;Joy&lt;/del&gt; Pain of Reading&lt;/h2&gt;
&lt;p&gt;It all begun about a month ago, when I needed to read more books to dig into a new subject. I had a pile of books staring at me and I simply couldn&amp;rsquo;t find enough courage to get started. I&amp;rsquo;ve always been a very lazy reader, cherry picking the content I needed to get my job done and only seldom enjoying what others called &amp;ldquo;the joy of reading&amp;rdquo;. Few exceptions aside, that &amp;ldquo;joy&amp;rdquo; was actually a frustrating pain.&lt;/p&gt;
&lt;p&gt;Most of the papers and other technical resources I had read during my 
&lt;a href=&#34;/about&#34;&gt;academic career&lt;/a&gt; had been an authentic pain, with only a few exceptions. I do a decent amount of reviewing work, both internal (not public, for the company I work for) and external (I sit in some 
&lt;a href=&#34;/about/#reviewing-others-work&#34;&gt;conferences review boards or technical commitees&lt;/a&gt;), and because of how review-oriented reading works, I pause reading very often to think about what I&amp;rsquo;ve just read, take notes, etc. So, slow reading, mostly. Truth is, I actually read a lot, but mainly because I have to, and I don&amp;rsquo;t quite realize how much I read. Possibly, this may have have created a negative bias about my actual reading abilities, to the point that starting and continuing a reading to the end is hard. Once I&amp;rsquo;m engaged, I get going, but getting started and concluding are the hardest parts.&lt;/p&gt;
&lt;h2 id=&#34;could-i-motivate-myself-to-read-more&#34;&gt;Could I Motivate Myself to Read More?&lt;/h2&gt;
&lt;p&gt;The Web is filled with &amp;ldquo;how to motivate yourself to do X, Y, Z&amp;rdquo; guides. Ironically, these many and diverse guides on the same subject not only means that people find them useful, but also that there are enough instances of X, Y, Z problems to make these guides worth existing! In simple words, many people suffer from X, Y, Z problems. So, you&amp;rsquo;re not alone. This post is not meant to be yet another of such guides, but just a summary of my recent experience.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; I&amp;rsquo;m not writing this post as a result of following one of those X, Y, Z guides. Actually, I found about a &lt;strong&gt;generic&lt;/strong&gt; &amp;ldquo;how to motivate yourself&amp;rdquo; guide, not about reading, which made me realize and reflect about the reasons why I&amp;rsquo;ve been reading more in the past month. I&amp;rsquo;m writing this in a retrospective way, not biased by the content of the guide I found. The guide&amp;mdash;which I&amp;rsquo;ll share below&amp;mdash;was helpful because it helped me understand the reasons of the change I had already embraced, without even noticing that.&lt;/p&gt;
&lt;h2 id=&#34;intrinsic-vs-extrinsic-motivation&#34;&gt;Intrinsic vs. Extrinsic Motivation&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;re familiar with the basics of psychology, you know that there exist two, broad types of motivation in incentive theories: 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Motivation#Incentive_theories:_intrinsic_and_extrinsic_motivation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;intrinsic (internal) motivation and extrinsic (external) motivation&lt;/a&gt;, and the latter is less powerful than the the former. When you&amp;rsquo;re intrinsically motivated to do something everything seems easy and smooth. For example, if you love your job you don&amp;rsquo;t perceive it as a due duty. If you like to play chess or cards, you look forward to play, regardless of any prizes. The prizes are external incentives that drive &lt;strong&gt;extrinsic&lt;/strong&gt; motivation. By the way, that&amp;rsquo;s how I interpret the last minute of 
&lt;a href=&#34;https://www.imdb.com/title/tt10048342/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Queen&amp;rsquo;s Gambit&lt;/a&gt;: &lt;em&gt;&amp;ldquo;sygrayem!&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Intrinsic vs. extrinsic motivation play an important role in &lt;strong&gt;education&lt;/strong&gt;. If educators are able to find and trigger intrinsic incentive mechanisms&amp;mdash;for instance by engaging the students with practical activities, involving them as &lt;strong&gt;part&lt;/strong&gt; of the teaching experience&amp;mdash;then the students are more likely to get intrinsically motivated to dig deeper into a subject&amp;hellip;for the sake of it! Students perform better with a good balance of intrinsic vs. extrinsic rewards, but both are necessary. Extrinsic rewards are often visible to others, so they become part of social interactions. Yes, I&amp;rsquo;m talking about grades. In the perfect system you study because you like the way the teacher teaches a subject, you get good grades (and you feel good the moment you get that reward!), other see those good grades and feel motivated to get good grades as well! On the other hand, if you only get extrinsic incentives&amp;mdash;grades only&amp;mdash;you won&amp;rsquo;t feel as good as when you get an intrinsic incentive, even when the grades are outstanding.&lt;/p&gt;
&lt;p&gt;Back to readings, when you get sucked into a novel or a story in the news, and want to continue reading, that&amp;rsquo;s your intrinsic motivation at play. You almost don&amp;rsquo;t perceive that you&amp;rsquo;re reading, you get so immersed that it&amp;rsquo;s almost like flying through the words. That&amp;rsquo;s what happened, very few cases, honestly (I should be pickier while choosing books!), when I found a book that was a true joy to read. There are many online social networks about readings (e.g., 
&lt;a href=&#34;https://www.goodreads.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Goodreads&lt;/a&gt;, 
&lt;a href=&#34;https://www.anobii.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anobii&lt;/a&gt;), which, in addition to recommending good books based on your past readings, show how much &lt;em&gt;others&lt;/em&gt; are reading. So, they make external (social) incentive factors into play: &amp;ldquo;look at how much your friend is reading&amp;rdquo;. I&amp;rsquo;ve tried some of them, but they never worked on me: I&amp;rsquo;m so slow at reading anyways that my social circle appears to be so far off me that I ended up closing the accounts because I found those numbers very depressing. Meh!&lt;/p&gt;
&lt;h2 id=&#34;the-microphone-that-brought-in-new-incentives&#34;&gt;The Microphone that Brought in New Incentives&lt;/h2&gt;
&lt;p&gt;At the beginning of the first lockdown I purchased a decent (not professional) microphone, because what I had ahead of me was, heh, lots of virtual conferences! I got myself a 
&lt;a href=&#34;https://www.trust.com/en/product/22400-gxt-252-emita-plus-streaming-microphone&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trust GTX 252+&lt;/a&gt;, which, considering the price range ($90&amp;ndash;100), has a quite good, warm sound.&lt;/p&gt;
&lt;p&gt;After recording the first presentation&amp;mdash;and get disappointed about the very scarce conference attendance&amp;mdash;I started to ponder how I could use that microphone in other ways. If you have small kids you know that doing actual work during lockdown is just a bliss. But small kids are a gold mine of opportunities and unexpected surprises. In this case my older one asked me to read him a book. He had &amp;ldquo;read&amp;rdquo; (through me and his mom) probably more than I&amp;rsquo;ve ever done in 6&amp;ndash;7 times his age. This time I told him: &lt;em&gt;&amp;ldquo;do you want to record the reading so you can share with your cousin?&amp;rdquo;&lt;/em&gt; And so I started recording my voice while reading his books, along with his (quite funny and entertaining) comments. We both enjoyed the activity, which we continued for about a month. Here you can see both an intrinsic incentive (reading became fun for both) as well as a social incentive (his cousin was happy to listen to his books whenever he wanted).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Commercial and/or professional recording of copyrighted material should adhere to copyright laws as well as follow any additional licenses that come with the material in question; so, if you ever think about doing this professionally, I recommend that you think about 
&lt;a href=&#34;https://www.google.com/search?q=how&amp;#43;to&amp;#43;become&amp;#43;an&amp;#43;audiobook&amp;#43;narrator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;starting a career as an audiobook narrator&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;read-for-someone-else-your-age&#34;&gt;Read for Someone Else (Your Age)&lt;/h2&gt;
&lt;p&gt;At this point you could be thinking that reading child books is painless&amp;mdash;to someone like with with poor reading habits&amp;mdash;because they&amp;rsquo;re short. True! And extremely boring to most adults, I&amp;rsquo;d say. Especially if you&amp;rsquo;ve been reading them every, single, day at bedtime for the past year or so. That&amp;rsquo;s probably why I stopped doing that after about a month 😆&lt;/p&gt;
&lt;p&gt;Meanwhile, about one month ago I started reading about 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Hermann_Ebbinghaus&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hermann Ebbinghaus&amp;rsquo; research on memory&lt;/a&gt;, and in particular about 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Spaced_repetition&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;spaced repetitions&lt;/a&gt;, a technique that he experimented on himself to memorize long lists of 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Pseudoword#Nonsense_syllables&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nonsense syllables&lt;/a&gt;. I was particularly intrigued by the fact that he used to read the target pseudowords aloud. And I had recetly learned about how the phonological loop of working memory works:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Subvocal rehearsal loop&lt;/strong&gt; (source: 
&lt;a href=&#34;https://www.oxfordreference.com/view/10.1093/oi/authority.20110803100540469&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Oxford reference&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;One of the two components of the phonological loop of working memory, functioning to keep information from decaying by mental repetition, and also translating visual information into phonological code where necessary for short-term memory. Also called an articulatory loop, an articulatory rehearsal loop, or an articulatory store.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, putting all the pieces together, I decided to run an experiment on myself: I read aloud one chapter of a book I was reading, used my new shiny microphone and 
&lt;a href=&#34;https://www.audacityteam.org/lwwwwww&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Audacity&lt;/a&gt; to record my voice, and I&amp;rsquo;ll listen to myself reading while doing other tasks, to see if I could memorize it better. I know, this does not replicate Ebbinghaus experiment, but bare with me, because at the end of the story this turns out to be just a pretext.&lt;/p&gt;
&lt;p&gt;At a first glance, here&amp;rsquo;s what I recall I felt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I felt extremely &lt;strong&gt;good and committed&lt;/strong&gt;, from the very first words I spoke;&lt;/li&gt;
&lt;li&gt;I could &lt;strong&gt;see&lt;/strong&gt; the &lt;strong&gt;progress&lt;/strong&gt; of my speech on the screen and the read pages quickly flipping;&lt;/li&gt;
&lt;li&gt;I felt focused and distraction free.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I thought it was a very good start and I didn&amp;rsquo;t even know what was coming!&lt;/p&gt;
&lt;h2 id=&#34;the-turning-point-helping-and-motivating-others&#34;&gt;The Turning Point: Helping and Motivating Others&lt;/h2&gt;
&lt;p&gt;Almost for fun, I shared the recorded audio among my reading group, just to hear their thoughts. When I shared the MP3 file among my friends, they inundated me with many thank-you messages and lots of blinky emojis. One of them in particular was the key, the turning point. They said:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;That&amp;rsquo;s awesome 😍 I felt so &lt;strong&gt;lost&lt;/strong&gt; these days, now you gave me a &lt;strong&gt;guiding voice&lt;/strong&gt; to listen to, and I can do that when I do my jogging! Thank you!!!!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;See that? That closed the loop! The fact that I was helping someone (BTW, a total stranger, because we run this reading group remotely among strangers!) to stay motivated is what motivated me most! I could almost envision this person doing their activities while listening to my &amp;ldquo;guiding voice&amp;rdquo; (I think that was the most powerful phrase). I felt what I was doing had positive value for someone, and that was the best, instantaneous reward I could get.&lt;/p&gt;
&lt;p&gt;A powerful social incentive!&lt;/p&gt;
&lt;h2 id=&#34;seeing-progress&#34;&gt;Seeing Progress&lt;/h2&gt;
&lt;p&gt;Remember when I said that I wasn&amp;rsquo;t incentivized to use Goodreads &amp;amp; friends because I felt slow at reading compared to my social circle? It turned out I was faster than I thought, and I could monitor my progress pretty quickly by looking at the folder where I kept my recordings on my computer. And those lists have been growing constantly on daily basis, and so the compliments I received by my reading group, thanking me for what I was doing.&lt;/p&gt;
&lt;p&gt;Seeing progress is the third ingredient towards behavior change. When we see the cumulative result of our work, we&amp;rsquo;re motivated to keep our behavior in that direction. But progress has to be measurable with an adequately-fine-grained unit. If you&amp;rsquo;re a lazy reader like me, and you&amp;rsquo;re measuring yourself by the number of books you read, then you&amp;rsquo;re stuck.&lt;/p&gt;
&lt;h2 id=&#34;the-tedx-talk-that-made-me-write-this&#34;&gt;The TEDx Talk That Made Me Write This&lt;/h2&gt;
&lt;p&gt;So, why am I writing this? Just because I wanted to share? Nah! I mean, yes, but not only that. Yesterday I watched 
&lt;a href=&#34;https://www.youtube.com/watch?v=xp0O2vi8DX4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this TEDx Cambridge&lt;/a&gt; talk by 
&lt;a href=&#34;https://www.ucl.ac.uk/pals/research/experimental-psychology/person/dr-tali-sharot/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Tali Sharot&lt;/a&gt;, a cognitive neuroscientist at 
&lt;a href=&#34;https://www.ucl.ac.uk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;UCL&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/xp0O2vi8DX4?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Prof. Sharot summarizes that it&amp;rsquo;s hard to change our behavior because most of our incentive programs are designed to &lt;em&gt;threaten&lt;/em&gt; us by showing us all the bad things that could happen if we don&amp;rsquo;t adopt that behavior, while her experiments show that the opposite incentive program is much more powerful (we&amp;rsquo;re talking about 15% vs 90%!). So, instead of bombard our kids with things like &lt;em&gt;&amp;ldquo;if you don&amp;rsquo;t read enough you&amp;rsquo;ll get bad grades&amp;rdquo;&lt;/em&gt; (which is what I&amp;rsquo;ve been bombarded with), let&amp;rsquo;s tell them &lt;em&gt;&amp;ldquo;if you read you&amp;rsquo;ll become the fastest reader in the world&amp;rdquo;&lt;/em&gt;. It&amp;rsquo;s intuitive, I know, but if you think about it, it&amp;rsquo;s quite hard to implement. Why? Because you have to design a good reward system around it, which should show immediate positive rewards over time. And that&amp;rsquo;s not always practical.&lt;/p&gt;
&lt;p&gt;So, the reason why I&amp;rsquo;m writing this piece is because Prof. Sharot&amp;rsquo;s talk enlightened me by showing all the ingredients that I already had on my plate, which were already at work to keep me motivated, but was quite nice to see them all condensed in that 15-minutes engaging talk, backed by scientific research!&lt;/p&gt;
&lt;p&gt;Overall, a good way to change your behavior consists of these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;use &lt;strong&gt;positive reward&lt;/strong&gt; as opposed to negative, threatening scenarios; by the way, this teaches a good lesson to many industry fields, which often makes use of 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Fear,_uncertainty,_and_doubt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FUD&lt;/a&gt; to spread supposedly convincing marketing messages and incentivize prospects to purchase more; and yes, that&amp;rsquo;s why disinformation spreads so well as opposed to clear, fact-based information.&lt;/li&gt;
&lt;li&gt;bring in &lt;strong&gt;social incentives&lt;/strong&gt;, so that you can see how others perceive your performance as well as compare yourself with others;&lt;/li&gt;
&lt;li&gt;find a way to &lt;strong&gt;monitor your progress&lt;/strong&gt; as fast as possible, to get you immediate, measurable rewards; delayed rewards don&amp;rsquo;t work well, or they should be broken down into smaller, spaced rewards.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hope you enjoyed reading this far, and please feel free to 
&lt;a href=&#34;/#contact&#34;&gt;reach out&lt;/a&gt; with any comments!&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tali Sharot, &lt;em&gt;&amp;ldquo;How to Motivate Yourself to Change Your Behavior&amp;rdquo;&lt;/em&gt;, TEDx Cambridge. 
&lt;a href=&#34;https://singjupost.com/how-to-motivate-yourself-to-change-your-behavior-tali-sharot-transcript/?singlepage=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Transcript&lt;/a&gt;, 
&lt;a href=&#34;https://www.youtube.com/watch?v=xp0O2vi8DX4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Susan Nolen-Hoeksema, Ernest R Hilgard, &lt;em&gt;&amp;ldquo;Atkinson and Hilgard&amp;rsquo;s Introduction to Psychology&amp;rdquo;&lt;/em&gt;, Cengage Learning, 2014, 16th edition. 
&lt;a href=&#34;https://www.worldcat.org/title/atkinson-and-hilgards-introduction-to-psychology/oclc/869786503&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Book details&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Hermann_Ebbinghaus&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hermann Ebbinghaus&lt;/a&gt;, Wikipedia. Viewed on: Dec 14th, 2020.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Spaced_repetition&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spaced Repetitions&lt;/a&gt;, Wikipedia. Viewed on: Dec 14th, 2020.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Pseudoword#Nonsense_syllables&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nonsense Syllables&lt;/a&gt;, Wikipedia. Viewed on: Dec 14th, 2020.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Smart Manufacturing Security</title>
      <link>/post/smart-manufacturing-security/</link>
      <pubDate>Mon, 08 Jun 2020 07:19:15 +0200</pubDate>
      <guid>/post/smart-manufacturing-security/</guid>
      <description>&lt;p&gt;How do we secure a smart manufacturing system, or a smart factory? Recent incidents such as the 
&lt;a href=&#34;https://thehackernews.com/2018/08/tsmc-wannacry-ransomware-attack.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ransomware infection that halted production at a major semiconductor foundry in 2018&lt;/a&gt; have already shown the impact of IT-to-OT lateral movement. Moreover, while smart manufacturing systems are isolated from other networks, there is a trend toward less isolation between IT and OT systems.&lt;/p&gt;
&lt;p&gt;My personal advise is to &lt;strong&gt;learn how to think as an attacker&lt;/strong&gt;. Knowing the current threats and countermeasures is indispensable, but you need to &lt;strong&gt;run an extra mile&lt;/strong&gt; and strive to think about &lt;em&gt;other&lt;/em&gt; ways that such a complex system can get compromised.&lt;/p&gt;
&lt;p&gt;In this series of brief videos, I&amp;rsquo;ll go through a 
&lt;a href=&#34;/publication/maggi_smartfactorywp_tr_2020/&#34;&gt;recent paper&lt;/a&gt; that I worked on: a collaborative research between 
&lt;a href=&#34;https://trendmicro.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trend Micro Research&lt;/a&gt; and 
&lt;a href=&#34;https://polimi.it&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Politecnico di Milano&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;ep-1-introduction-to-smart-manufacturing-security&#34;&gt;Ep. 1: Introduction to Smart Manufacturing Security&lt;/h2&gt;
&lt;p&gt;In this video we start by taking a look at how a smart manufacturing system actually looks like, using the system that we have used during our research.
Although it&amp;rsquo;s an educational lab, it uses the same equipment used in real modern factories.&lt;/p&gt;
&lt;p&gt;
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/7q7eun--K30?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;There are 7 stations, each controlled by a dedicated PLC and an HMI for the operator to interact with the system, for maintenance or troubleshooting for example. The goal of the plant is to produce cell phones (actually, toy cell phones) with a case and a printed circuit board inside. The whole system is controlled by a so-called MES (or manufacturing execution system) which is a scheduling software that make sure that each PLC receives the right control command at the right time, and that all the parts needed to produce an item are available.&lt;/p&gt;
&lt;p&gt;The SIEMENS equipment (such as the HMIs and PLCs) communicate via S7, which is a proprietary control protocol by SIEMENS. The MES and other components communicate via Modbus and OPC Unified Architecture, which is an open machine-to-machine protocol for industrial automation
There&amp;rsquo;s a lot of &amp;ldquo;backstage&amp;rdquo; work done by the engineers who setup these systems, which is normally carried out by the so-called &amp;ldquo;engineering workstation&amp;rdquo;: it&amp;rsquo;s a computer with industrial automation programming software installed, normally directly connected to all the machines.&lt;/p&gt;
&lt;p&gt;Although the trend is towards more and more connected smart manufacturing systems, we&amp;rsquo;re assuming a conservative scenario, in which none of these systems is directly reachable from the Internet.&lt;/p&gt;
&lt;p&gt;We conclude the video with the questions that we wanted to answer with this research:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Under which conditions are certain attacks possible, and what is their impact?&lt;/strong&gt; Of course even a simple ransomware or any other &amp;ldquo;traditional&amp;rdquo; IT attacks can have repercussions on the OT environment, even if that wasn&amp;rsquo;t the primary goal of the attacker. But we&amp;rsquo;re more interested in attacks against the specific smart-manufacturing technology&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Are there any overlooked attack vectors that could make the attacker&amp;rsquo;s job easier?&lt;/strong&gt; We&amp;rsquo;re interested in non-mainstream opportunities, or techniques that attackers could use to &amp;ldquo;fly under the radar&amp;rdquo; or that we think they&amp;rsquo;ll use in the future.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What is the security impact of the current software-development practices, including the use of open libraries, with complex interdependencies?&lt;/strong&gt; We&amp;rsquo;ll see how a missing check in a library included in the firmware of an industrial device may lead to full compromise of the entire manufacturing plant.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What is the cybersecurity awareness level of the technical personnel who engineer, program, and operate in smart manufacturing environments?&lt;/strong&gt; While it&amp;rsquo;s undeniable that the priorities of a perfectly functioning OT system are in contrast with the priorities of a perfectly secure IT system, one of the goals of this research was to understand exactly why this is the case, and what the cybersecurity industry can do about it.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ep-2-malicious-industrial-software-extensions&#34;&gt;Ep. 2: Malicious Industrial Software Extensions&lt;/h2&gt;
&lt;p&gt;In this video we focus on the engineering workstation (EWS), which is a crucial endpoint used to program the logic of a smart manufacturing plant. It&amp;rsquo;s essential in any smart factory station, it should never be exposed or reachable from a public network, but we show that even if not directly reachable, an attacker can still find ways to access it.&lt;/p&gt;
&lt;p&gt;
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/jiyb6BKx_TA?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;In this second episode I show you how future smart factories could be infected via malicious software extensions, a new way to deliver software for industrial automation. Malicious software extensions and future industrial &amp;ldquo;app stores&amp;rdquo; represent a relevant but overlooked attack vector for smart factory environments.&lt;/p&gt;
&lt;p&gt;Thanks to our research ABB&amp;rsquo;s RobotApps Store has fixed an upload bypass vulnerability that would have allowed anyone to upload (malicious) software extensions that could cripple into the engineering workstation, a critical endpoint used to program industrial machines such as robots.&lt;/p&gt;
&lt;h2 id=&#34;extra-episode-lateral-movements-via-industrial-automation-scripts&#34;&gt;Extra Episode: Lateral Movements via Industrial Automation Scripts&lt;/h2&gt;
&lt;p&gt;In this video we focus on two questions: What if a perfectly patched industrial manufacturing machine can still harbor for vulnerabilities where no one is looking? What if the powerful programming languages used to program these machines can go beyond simple movement instructions, and actually allow threat actors to hide malware into the logic?&lt;/p&gt;
&lt;p&gt;
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/g2h2EQWan3E?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;In this unplanned, extra episode you can see the entire picture, from entry point (already glanced at in the second episode) to vulnerability exploitation and complete system compromise.&lt;/p&gt;
&lt;p&gt;And of course we conclude with an overview of the short-, medium-, and long-term remediation approaches.&lt;/p&gt;
&lt;h2 id=&#34;upcoming-videos&#34;&gt;Upcoming Videos&lt;/h2&gt;
&lt;p&gt;In the following videos we&amp;rsquo;ll see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how an attacker can access a smart manufacuring system through a trojanized IoT library,&lt;/li&gt;
&lt;li&gt;then we&amp;rsquo;ll see how a weak mobile HMI could facilitate the job of an attacker,&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Marcello Pogliani&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;/publication/maggi_smartfactorywp_tr_2020/&#34;&gt;Attacks on Smart Manufactururing Systems: A Forward-looking Security Analysis&lt;/a&gt;.
  &lt;em&gt;Trend Micro Research&lt;/em&gt;.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;https://www.trendmicro.com/vinfo/us/security/news/internet-of-things/threats-and-consequences-a-security-analysis-of-smart-manufacturing-systems&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/maggi_smartfactorywp_tr_2020/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Marcello Pogliani&lt;/span&gt;, &lt;span&gt;Martino, Vittone&lt;/span&gt;, &lt;span&gt;Davide Quarta&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;, &lt;span&gt;Marco Balduzzi&lt;/span&gt;, &lt;span&gt;Rainer Vosseler&lt;/span&gt;, &lt;span&gt;Martin Rösler&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;/publication/maggi_rogueautomationwp_tr_2020/&#34;&gt;Rogue Automation: Vulnerable and Malicious Code in Industrial Programming&lt;/a&gt;.
  &lt;em&gt;Trend Micro Research&lt;/em&gt;.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;https://www.trendmicro.com/vinfo/us/security/news/internet-of-things/unveiling-the-hidden-risks-of-industrial-automation-programming&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/maggi_rogueautomationwp_tr_2020/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Radio Killed the Radio Stars: Security Analysis of RF Protocols for Industrial Applications</title>
      <link>/post/ir-security/</link>
      <pubDate>Wed, 16 Jan 2019 16:01:50 +0200</pubDate>
      <guid>/post/ir-security/</guid>
      <description>&lt;p&gt;After having analyzed the several RF protocols for industrial applications,
distributed by global vendors, we discovered that none of them had
sufficient security features to prevent an attacker from hijacking the
communication and manoeuvre the controlled connected machines.&lt;/p&gt;
&lt;p&gt;In Summer 2016 the condo we live in went through some renovation work. We had
construction workers here for the about half a year. This was around the time
when I was getting into software-defined radio (SDR) technology, and had
a spectrum analyzer open all the time on my computer. Just for fun. After
a while I&amp;rsquo;ve noticed some peaks of energy around 434MHz. I didn&amp;rsquo;t pay
attention, until when I saw one of the workers holding what looked like
a rugged remote controller with a tiny antenna. I rushed back in my office and
took a closer look at the spectrum: I could clearly see that the peaks were
showing in perfect sync with the noise of the huge crane swinging over my roof.&lt;/p&gt;
&lt;p&gt;I had a little chat with the worker and asked him: &amp;ldquo;Is there any safety
mechanism? Like, if I push a button to make the load go down, and someone is
under that load, what happens?&amp;rdquo; In the local dialect, he answered something
that I could roughly translate as&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;🤬  if you do that, you must have some serious problems.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This sounded like the perfect project idea to pitch to my colleagues! So I did.
After some back and forth, brainstorming, and someone in the team having
related ideas, we&amp;rsquo;ve decided to go after this, map the market, reverse engineer
the protocols, look in depth into the embedded systems inside these remotes,
and perform an all-around security analysis.&lt;/p&gt;
&lt;p&gt;So here we are. After a long break in the middle, hard research work, and
a challenging disclosure process, I&amp;rsquo;m very happy to share the results of what
my colleagues in Trend Micro Research and I have produced.&lt;/p&gt;
&lt;p&gt;Meanwhile, the renovation work is done and we&amp;rsquo;re enjoying a shiny new stone
paver.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/ir-security/condo.jpg&#34; alt=&#34;End of the renovation work.&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;radio-frequency-technology&#34;&gt;Radio-frequency Technology&lt;/h2&gt;
&lt;p&gt;Sub-gigaherz radio-frequency (RF) protocols are widely adopted for both
consumer and &lt;strong&gt;industrial applications&lt;/strong&gt;. From simple garage-door openers to
remote controllers that manoeuvre huge mining drillers or overhead cranes that
can lift tons of loads. So, way beyond construction cranes. These RF protocols
operate in the ISM bands (e.g., 433, 868, 915 MHz, depending on the region),
have a &lt;strong&gt;range up to several hundreds meters&lt;/strong&gt;, can easily go through
obstacles, are very low priced, and are very flexible.&lt;/p&gt;
&lt;h2 id=&#34;industrial-rf-remote-control-systems&#34;&gt;Industrial RF Remote Control Systems&lt;/h2&gt;
&lt;p&gt;These industrial remote-control systems usually comprise a receiver (RX) with
a few relay switches (e.g., to power up the controlled motor or other
electrical loads), and a transmitter (TX) that looks like a rugged remote
controller with buttons. Both RX and TX have an &lt;strong&gt;embedded digital radio chip&lt;/strong&gt;
and a micro-controller that implements the actual application-level protocol
(e.g., structure of messages, CRCs, pairing, addressing). Each transmitted
message carries a distinct &lt;strong&gt;command&lt;/strong&gt; that the RX actuates, usually by
triggering the relay switches in a given, configurable way.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/ir-security/ir-system.jpg&#34; alt=&#34;Industrial Radio Remote Control System in a Nutshell&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;security-angle&#34;&gt;Security Angle&lt;/h2&gt;
&lt;p&gt;Despite the simplicity of these systems, &lt;strong&gt;there is no standardization&lt;/strong&gt; in the
application-level protocol, nor security best practices that go beyond the use
of rolling-code to avoid replay attacks (in the best case).&lt;/p&gt;
&lt;p&gt;After having analyzed the systems produced by several global vendors, in our
research we discovered that none of the implementations had any robust security
features (not even rolling codes) that would prevent an attacker from hijacking
the communication and take control of the heavy industrial machines connected
to the RX unit. After having responsibly disclosed our findings through 
&lt;a href=&#34;https://www.zerodayinitiative.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trend
Micro&amp;rsquo;s ZDI&lt;/a&gt; (
&lt;a href=&#34;/advisories/&#34;&gt;10 advisories and 3 ICS-CERT
alerts&lt;/a&gt;, some of which resulted in security firmware updates), we&amp;rsquo;ve drawn
a list of recommendations for end users, system integrators, and vendors, to
ensure that current-generation systems get properly secured, and that
next-generation systems will be secure by design.&lt;/p&gt;
&lt;h2 id=&#34;details-nope&#34;&gt;Details? Nope!&lt;/h2&gt;
&lt;p&gt;This has been the hard part. Digging into custom protocols and figuring out
all the bits that travel on the SPI bus (to make sure that we&amp;rsquo;re looking
at the right data on the RX side) was challenging, yet a lot, lot of fun!&lt;/p&gt;
&lt;p&gt;No, this blog post won&amp;rsquo;t go into the details. There&amp;rsquo;s the white paper (below)
for that! Plus 
&lt;a href=&#34;https://www.trendmicro.com/vinfo/us/security/news/vulnerabilities-and-exploits/attacks-against-industrial-machines-via-vulnerable-radio-remote-controllers-security-analysis-and-recommendations&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this interactive page with demo videos&lt;/a&gt;, and 
&lt;a href=&#34;https://blog.trendmicro.com/trendlabs-security-intelligence/demonstrating-command-injection-and-e-stop-abuse-against-industrial-radio-remote-controllers/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this blog post that describes a little RF dongle we&amp;rsquo;ve built for this research&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve presented this research at 
&lt;a href=&#34;https://direction.trendmicro.com/sess/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Direction Tokyo last
November&lt;/a&gt; (by the way, my first
encounter with the Japanese culture was stellar!), my colleague

&lt;a href=&#34;https://twitter.com/miaoski&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Philippe&lt;/a&gt; has presented 
&lt;a href=&#34;https://hitcon.org/2018/pacific/downloads/1213-R1/1610-1650.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;it at HITCON
pacific&lt;/a&gt;
focusing on the firmware reverse-engineering, and my colleagues

&lt;a href=&#34;https://www.linkedin.com/in/jonathan-andersson-b516b9/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonathan&lt;/a&gt;
(
&lt;a href=&#34;https://www.engadget.com/2016/10/28/icarus-hijack-dmsx-drones/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt;
Jonathan) and 
&lt;a href=&#34;https://twitter.com/sjhilt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stephen&lt;/a&gt; have just presented the
white paper today at 
&lt;a href=&#34;https://s4xevents.com/sessions/the-industrial-radio-project/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the S4
conference&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;media&#34;&gt;Media&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;m not attempting to keep track of the media activity around this research, sorry!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://monoist.atmarkit.co.jp/mn/articles/1811/19/news054.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;あなたの機械、安易につなげて大丈夫？　リスクと攻撃手法を知る&lt;/a&gt;, Nov 19th, 2018&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://www.itmedia.co.jp/news/articles/1811/29/news027.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;クレーンを不正に遠隔操作、10年前より「攻撃しやすい」？　専門家が注意喚起&lt;/a&gt;, Nov 29th, 2018&lt;/li&gt;
&lt;li&gt;Scott Shuey, Gulf News, 
&lt;a href=&#34;https://gulfnews.com/technology/the-next-cyber-threat-wont-be-over-the-internet-its-on-the-radio-1.61093289&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The next cyber threat won’t be over the internet, it’s on the radio&lt;/a&gt; (
&lt;a href=&#34;http://gulfnews.newspaperdirect.com/epaper/viewer.aspx?issue=11252019010400000000001001&amp;amp;page=18&amp;amp;article=47eb5960-bdd2-487e-a806-eca02e63fc0e&amp;amp;key=KkfY%2BCKWAUSFjN6c%2Fj%2Bzmg%3D%3D&amp;amp;feed=rss&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;print version&lt;/a&gt;). Jan 5th, 2019&lt;/li&gt;
&lt;li&gt;Thomas Brewster, Forbes, 
&lt;a href=&#34;https://www.forbes.com/sites/thomasbrewster/2019/01/15/exclusive-watch-hackers-take-control-of-giant-construction-cranes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Watch Hackers Take Control Of Giant Construction Cranes&lt;/a&gt;. Jan 15th, 2019&lt;/li&gt;
&lt;li&gt;Sean Lyngaas, CyberScoop, 
&lt;a href=&#34;https://www.cyberscoop.com/crane-hack-radio-frequency-trend-micro-s4x19/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Look to the sky: How hackers could control cranes by abusing radio frequencies&lt;/a&gt;, Jan 15th, 2019&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Marco Balduzzi&lt;/span&gt;, &lt;span&gt;Jonathan Andersson&lt;/span&gt;, &lt;span&gt;Philippe Lin&lt;/span&gt;, &lt;span&gt;Stephen Hilt&lt;/span&gt;, &lt;span&gt;Akira Urano&lt;/span&gt;, &lt;span&gt;Rainer Vosseler&lt;/span&gt;
  &lt;/span&gt;
  (2019).
  &lt;a href=&#34;/publication/maggi_industrialradios_2019/&#34;&gt;A Security Evaluation of Industrial Radio Remote Controllers&lt;/a&gt;.
  &lt;em&gt;Proceedings of the 16th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA)&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/maggi_industrialradios_2019/maggi_industrialradios_2019.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/maggi_industrialradios_2019/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Jonathan Andersson&lt;/span&gt;, &lt;span&gt;Marco Balduzzi&lt;/span&gt;, &lt;span&gt;Stephen Hilt&lt;/span&gt;, &lt;span&gt;Philippe Lin&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Akira Urano&lt;/span&gt;, &lt;span&gt;Rainer Vosseler&lt;/span&gt;
  &lt;/span&gt;
  (2019).
  &lt;a href=&#34;/publication/andersson_industrialradioswp_tr_2019/&#34;&gt;A Security Analysis of Radio Remote Controllers for Industrial Applications&lt;/a&gt;.
  &lt;em&gt;Trend Micro Research&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/andersson_industrialradioswp_tr_2019/andersson_industrialradioswp_tr_2019.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/andersson_industrialradioswp_tr_2019/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Large Scale Analysis of Defaced Web Pages</title>
      <link>/post/large-scale-deface-page-analysis/</link>
      <pubDate>Thu, 14 Jun 2018 15:21:19 +0200</pubDate>
      <guid>/post/large-scale-deface-page-analysis/</guid>
      <description>&lt;p&gt;Given the multiple releases around this topic and project, I&amp;rsquo;ve decided to
put together a summary. So far, there is: a tool, a white paper, an
academic paper, and (spoiler alert) another white paper coming soon.&lt;/p&gt;
&lt;p&gt;You’d be surprised (I was!) how much the modus operandi and the motivation
behind web defacement have evolved and mutated over the past ~20 years. From
attackers interested in pointing their finger to vulnerable websites, to modern
actors taking strong positions on real-world conflicts.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/large-scale-deface-page-analysis/i/real-world-timeline.jpg&#34; alt=&#34;Timeline of real world events for which we have found evidence in web-deface pages.&#34; title=&#34;Timeline of Real World Events&#34;&gt;&lt;/p&gt;
&lt;p&gt;How do we know what we know about this phenomenon? Let&amp;rsquo;s take a look!&lt;/p&gt;
&lt;h2 id=&#34;the-tool&#34;&gt;The Tool&lt;/h2&gt;
&lt;p&gt;Last year at 
&lt;a href=&#34;https://twitter.com/toolswatch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Black Hat US Arsenal&lt;/a&gt; my
colleagues and I released 
&lt;a href=&#34;https://github.com/trendmicro/defplorex&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;part of the source code of
DefPloreX&lt;/a&gt;, the tool-chain that we use
to explore million of web-deface pages. DefPloreX is pretty flexible and, in
principle, it could be used to process any web page, for instance those planted
as a result of an attack, or to &amp;ldquo;cluster&amp;rdquo; together web pages of underground web
sites, and any other e-crime forensics task that requires to &amp;ldquo;make sense&amp;rdquo; out
of a large dataset of web pages.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/trendmicro/defplorex/blob/master/i/dpx-overall.png?raw=true&#34; alt=&#34;DefPloreX workflow&#34; title=&#34;DefPloreX workflow&#34;&gt;&lt;/p&gt;
&lt;p&gt;DefPloreX ingests plain and flat tabular files (e.g., CSV files) containing
metadata records of web incidents under analysis (e.g., URLs), renders them and
obtains a copy of their resources with headless browsers (we tried basically
all of them, but then we settled with Chrome via

&lt;a href=&#34;https://github.com/GoogleChrome/puppeteer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Puppeteer&lt;/a&gt;), extracts numerical
features, and stores the resulting data to an Elastic index. We&amp;rsquo;ve designed any
task to be distributed by default, using Celery to coordinate them.&lt;/p&gt;
&lt;p&gt;On top of the Elastic back-end, I&amp;rsquo;ve cooked up a ReactJS-based web-app (which
as of now is not part of the open-source release, mainly because the code is
&lt;strong&gt;very&lt;/strong&gt; messy) to interactively explore, query, and dig into the data. This
allows an analyst to easily investigate on campaigns, for example in
discovering websites targeted by the same campaign or attributing one or more
actors to the same hacking group. All of this without sacrificing the
interactivity aspect of the investigation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/trendmicro/defplorex/blob/master/i/dpx-clusters-viz.png?raw=true&#34; alt=&#34;DefPloreX web app main screen&#34; title=&#34;DefPloreX web app main screen&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you want to see the web app in action, you can take yourself a 14 minutes coffee or tea break while watching this demo.&lt;/p&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/DILbSXYpiMU?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h3 id=&#34;distributed-data-processing&#34;&gt;Distributed Data Processing&lt;/h3&gt;
&lt;p&gt;Normally, to take full advantage of Elastic&amp;rsquo;s distributed data-processing
functionality, you need to resort to

&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scripting&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Although scripting is quite powerful and handy for small data-manipulation
tasks, it&amp;rsquo;s a bit cumbersome to deploy and handle requires; and, in addition,
it requires full access to the Elastic&amp;rsquo;s client nodes. For example, if you need
to process all the documents in an Elastic index (e.g., to enrich them by
computing additional fields), you will have to choose one of the scripting
languages supported by Elastic, write a script, deploy it and run it. Needless
to say, your script will run within the context of the ES runtime, with all the
limitations that this implies. For example, should you need to use Python,
you&amp;rsquo;re forced to use the Jython Java implementation of Python, which is not the
same as pure Python. For instance, some of the libraries that you may want to
use may not be supported, and so on. In other words, we don&amp;rsquo;t want to depend on
the Elastic&amp;rsquo;s scripting subsystem in our work :-)&lt;/p&gt;
&lt;p&gt;Instead, we take a more &amp;ldquo;detached&amp;rdquo; approach. We decouple the data-processing
part, making it independent from the Elastic runtime and architecture, and rely
on ES exclusively as a data back-end to store, retrieve and modify JSON
documents. The coordination of the distributed computation is delegated to
a well-known and widely used distributed task queue:

&lt;a href=&#34;http://www.celeryproject.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Celery&lt;/a&gt;. The friendliness of Celery is
astonishing: from the programmer&amp;rsquo;s perspective, all it requires is to write
your data-processing code by means of a function, and Celery will take care of
offloading the (expensive and long-running) computation to one of the available
workers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/trendmicro/defplorex/blob/master/i/dpx-celery.png?raw=true&#34; alt=&#34;DefPloreX distributed data processing via Celery&#34; title=&#34;DefPloreX distributed data processing via Celery&#34;&gt;&lt;/p&gt;
&lt;p&gt;For example, if you need to visit a web page with an automated headless
browser, all you need to do is to wrap your code into a function, let&amp;rsquo;s say
&lt;code&gt;visit_page&lt;/code&gt;, and decorate it with &lt;code&gt;@app.task&lt;/code&gt; to inform Celery that this is
a task:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@app.task
def visit_page(url):
    result = long_running_process(url)

    return result
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Later on in your code, all you need to do is to call the function (almost) as
you would normally do:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;visit_page.delay(url)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;.delay()&lt;/code&gt; function indicates that the function call will not execute
immediately, but instead will be &amp;ldquo;pushed&amp;rdquo; into a task list, from which an
available worker will pull it and do the work.&lt;/p&gt;
&lt;p&gt;On the other end of the task list, you can launch as many workers as you need,
by simply keeping the Celery daemon active:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;$ celery worker --autoscale=6,64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Assuming a 64-core machine, this command spawns 6 concurrent processes, up to
64 when more workload comes in. And of course you can add as many workers as
needed, from a single computer with a few tenths of cores, to a full rack
distributed across the globe. In our deployment, we have 5 machines, with
a total of 128 cores. With these modest resources, we were able to visit the
entire collection of over 13 million web pages in a week. Adding more cores
would have made the analysis even faster.&lt;/p&gt;
&lt;h3 id=&#34;document-transformations&#34;&gt;Document Transformations&lt;/h3&gt;
&lt;p&gt;From this moment on, we have a solid foundation to efficiently transform JSON
documents stored in the Elastic index. Therefore, we &amp;ldquo;encode&amp;rdquo; any operation
that we need to perform in DefPloreX by means of a few lines of Python code. For
example, we often need to &amp;ldquo;tag&amp;rdquo; JSON documents to mark those that have been
processed. To this end, as exemplified in this repository, we use the
&lt;code&gt;TagTransformer&lt;/code&gt; transformation. As any other transform, this function receives one JSON
document and returns the newly added fields, or the modified fields.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class TagTransformer(Transformer):
    &amp;quot;&amp;quot;&amp;quot;
    Example transform to append tag to a record.
    &amp;quot;&amp;quot;&amp;quot;
    _name = &#39;tag&#39;                   # unique name

    def __call__(self, doc, *args, **kwargs):
        doc = super(TagTransformer, self).__call__(
                doc, *args, **kwargs)

        tag = kwargs.get(&#39;tag&#39;)     # tag that we want to apply to the JSON

        if not tag:
            log.debug(&#39;No tags supplied, skipping&#39;)
            return []

        tags = doc.get(&#39;tags&#39;, [])  # get the &#39;tags&#39; field from the existing JSON doc

        if tags:
            log.debug(&#39;Found tags: %s&#39;, tags)

        tags.append(tag)            # append the new tag
        tags = list(set(tags))      # remove duplicates

        log.debug(&#39;Updated tags: %s&#39;, tags)

        return dict(tags=tags)      # return the enriched JSON
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of this transformation is automatically handled by our Elastic
wrapper (see &lt;code&gt;backend.elastic.ESStorer&lt;/code&gt;) and the
&lt;code&gt;transformer.Pipeline&lt;/code&gt; class, which merges the new (partial) document with the
original one and saves it into the ES index. Actually, this is
performed in bulk: that is, every worker consumes and processes a given amount
of documents at each round (default is 1000). To summarize: given a query, we
enqueue all the IDs of the documents that match that query. The queue consumers
will pull 1000 IDs at a time, query Elastic for the respective documents,
transform them, and push them back on Elastic as update operations.&lt;/p&gt;
&lt;p&gt;Other transformations that we have implemented (briefly explained in
the following) include for example visiting the web pages with an automated,
headless browser, extracting information from the visited web pages,
calculating numerical features, and so on. Every task is expressed by means of
a subclass of &lt;code&gt;Transformer&lt;/code&gt;, which takes as input a document, and returns the
enriched or modified fields.&lt;/p&gt;
&lt;h2 id=&#34;the-white-paper&#34;&gt;The White Paper&lt;/h2&gt;
&lt;p&gt;With the help of our great colleagues at TrendLabs, we prepared a 
&lt;a href=&#34;https://www.trendmicro.com/vinfo/us/security/news/cyber-attacks/web-defacements-exploring-the-methods-of-hacktivists&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;white
paper&lt;/a&gt;
that focuses on the major campaigns, and how DefPloreX helped explore them. In
particular, we look at 7 campaigns that have affected Israel, France,
India, Syria, Kosovo, and countries surrounding the South China Sea. We dig
into specific conflicts in those areas and the defacements that happened in the
aftermath.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/large-scale-deface-page-analysis/i/wp.jpg&#34; alt=&#34;A Deep Dive into Defacement: How Geopolitical Events Trigger Web Attacks&#34; title=&#34;A Deep Dive into Defacement: How Geopolitical Events Trigger Web Attacks&#34;&gt;&lt;/p&gt;
&lt;p&gt;To ~~feed our curiosity and~~~ help CERTs understand better the origin of these
attacks and modus-operandi of the groups, we also look how they are organized
(some are formed across continents, and some are a loose collection of local
hackers), as well as how their recruitment tools and the methods adopt.&lt;/p&gt;
&lt;h2 id=&#34;the-devil-answer-is-in-the-details&#34;&gt;The &lt;del&gt;Devil&lt;/del&gt; Answer is in the Details&lt;/h2&gt;
&lt;p&gt;You might be wondering how exactly the data-mining workflow works, what
features we use, what clustering algorithm and so on. For the impatient, here&amp;rsquo;s a quick overview of the data that we process and the features that we extract:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/large-scale-deface-page-analysis/i/data.jpg&#34; alt=&#34;Metadata and raw content available in our dataset, along with a description of the trustworthiness of each attribute.&#34; title=&#34;Metadata and raw content available in our dataset, along with a description of the trustworthiness of each attribute.&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/large-scale-deface-page-analysis/i/features.jpg&#34; alt=&#34;Clustering features that we extract from each deface page.&#34; title=&#34;Clustering features that we extract from each deface page.&#34;&gt;&lt;/p&gt;
&lt;p&gt;So, now, how do we use these features for clustering?&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m very thankful to Roberto Perdisci for the valuable insights that he
provided on this work about the machine-learning and data-mining part. What I&amp;rsquo;m
most thankful about, however, is the suggestion to use BIRCH, which I didn&amp;rsquo;t
know before. I think this figure speaks by itself.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/large-scale-deface-page-analysis/i/dbscan-vs-birch.jpg&#34; alt=&#34;BIRCH vs. DBSCAN.&#34; title=&#34;BIRCH vs. DBSCAN.&#34;&gt;&lt;/p&gt;
&lt;p&gt;Impressive, huh?&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;
  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Marco Balduzzi&lt;/span&gt;, &lt;span&gt;Ryan Flores&lt;/span&gt;, &lt;span&gt;Lion Gu&lt;/span&gt;, &lt;span&gt;Vincenzo Ciancaglini&lt;/span&gt;
  &lt;/span&gt;
  (2018).
  &lt;a href=&#34;/publication/maggi_defplorex_2018/&#34;&gt;Investigating Web Defacement Campaigns at Large&lt;/a&gt;.
  &lt;em&gt;Proceedings of the 2018 on Asia Conference on Computer and Communications Security&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/maggi_defplorex_2018/maggi_defplorex_2018.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/maggi_defplorex_2018/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Marco Balduzzi&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Vincenzo Ciancaglini&lt;/span&gt;, &lt;span&gt;Ryan Flores&lt;/span&gt;, &lt;span&gt;Lion Gu&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;/talk/balduzzi_defplorexbhus_talk_2017/&#34;&gt;DefPloreX: A Machine Learning Toolkit for Large-scale e-Crime Forensics&lt;/a&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/talk/balduzzi_defplorexbhus_talk_2017/balduzzi_defplorexbhus_talk_2017.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/talk/balduzzi_defplorexbhus_talk_2017/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;











  
  
    
  
&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;https://www.youtube.com/watch?v=DILbSXYpiMU&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Video
&lt;/a&gt;




&lt;/p&gt;

  
  
&lt;/div&gt;

&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dnsmasq and CVE-2017-1449*: A Reality Check and Remediation Practices</title>
      <link>/post/dnsmasq/</link>
      <pubDate>Sat, 07 Oct 2017 15:09:24 +0200</pubDate>
      <guid>/post/dnsmasq/</guid>
      <description>&lt;p&gt;Many vulnerabilities in one shot, yet several pre-conditions for a target to
be actually exploitable. Here&amp;rsquo;s simple flowchart to check whether your
Dnsmasq deployments are vulnerable.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.thekelleys.org.uk/dnsmasq/doc.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dnsmasq&lt;/a&gt; is the de-facto tool
to implement DNS and DHCP services in small servers and embedded devices. Being
Dnsmasq user, when 
&lt;a href=&#34;https://security.googleblog.com/2017/10/behind-masq-yet-more-dns-and-dhcp.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Security researchers disclosed the CVE-2017-14491 to
14496
series&lt;/a&gt;,
I quickly checked whether my installation was vulnerable.&lt;/p&gt;
&lt;p&gt;Turned out that, despite I found a vast amount of devices running a vulnerable
version of Dnsmasq, the chain of pre-conditions for these vulnerabilities to be
exploitable are not super trivial. So I decided to write them down in
a flowchart.&lt;/p&gt;
&lt;p&gt;You can read 
&lt;a href=&#34;http://blog.trendmicro.com/trendlabs-security-intelligence/dnsmasq-reality-check-remediation-practices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the full blog post here&lt;/a&gt;!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Robosec: Industrial Robot Security</title>
      <link>/post/robosec/</link>
      <pubDate>Thu, 31 Aug 2017 17:39:31 +0200</pubDate>
      <guid>/post/robosec/</guid>
      <description>&lt;p&gt;Industrial robots are complex cyber-physical systems used for manufacturing,
and a critical component of any modern factory. Besides the mechanical arm,
inside an industrial robot there are not just electromechanical components but
a multitude of complex embedded controllers.&lt;/p&gt;
&lt;p&gt;These embedded controllers are often interconnected with other computers in
the factory network, safety systems, and to the Internet for remote
monitoring and maintenance. In this scenario, industrial routers also play a
key role, because they directly expose the robot&amp;rsquo;s controller. Therefore, the
impact of a single, simple vulnerability can grant attackers an easy entry
point.&lt;/p&gt;
&lt;h2 id=&#34;videos&#34;&gt;Videos&lt;/h2&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/BxHYtFlKruY?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;br /&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/ufLyfUnzZRY?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;read-more&#34;&gt;Read More&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Technical brief:&lt;/strong&gt; 
&lt;a href=&#34;https://www.trendmicro.com/vinfo/us/security/news/internet-of-things/rogue-robots-testing-industrial-robot-security&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rogue Robots: Testing the Limits of an Industrial Robot’s Security&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Material, F.A.Q., press:&lt;/strong&gt; 
&lt;a href=&#34;http://robosec.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://robosec.org&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Elevator pitch:&lt;/strong&gt; 
&lt;a href=&#34;https://www.youtube.com/watch?v=mmmvwmDq-UM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rogue Robots - Testing the Limits of an Industrial Robot’s Security&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;
  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Davide Quarta&lt;/span&gt;, &lt;span&gt;Marcello Pogliani&lt;/span&gt;, &lt;span&gt;Mario Polino&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Zanero Stefano&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;/talk/quarta_robosecbhus_talk_2017/&#34;&gt;Breaking the Laws of Robotics: Attacking Industrial Robots&lt;/a&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/talk/quarta_robosecbhus_talk_2017/quarta_robosecbhus_talk_2017.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/talk/quarta_robosecbhus_talk_2017/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;











  
  
    
  
&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;https://www.youtube.com/watch?v=RKLUWnzIaP4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Video
&lt;/a&gt;




&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Davide Quarta&lt;/span&gt;, &lt;span&gt;Marcello Pogliani&lt;/span&gt;, &lt;span&gt;Mario Polino&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Andrea Maria Zanchettin&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;/publication/quarta_robosec_2017/&#34;&gt;An Experimental Security Analysis of an Industrial Robot Controller&lt;/a&gt;.
  &lt;em&gt;Proceedings of the 38th IEEE Symposium on Security and Privacy&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/quarta_robosec_2017/quarta_robosec_2017.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/quarta_robosec_2017/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;











  
  
    
  
&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;https://www.youtube.com/watch?v=X3fUNWRgeao&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Video
&lt;/a&gt;




&lt;/p&gt;

  
  
&lt;/div&gt;

&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>From a Bit-flipping to a Vulnerability in the CAN Standard</title>
      <link>/post/candos/</link>
      <pubDate>Wed, 16 Aug 2017 12:49:04 +0200</pubDate>
      <guid>/post/candos/</guid>
      <description>&lt;p&gt;CAN-based protocols are vulnerable to bit-flipping attacks at the link layer.
In this collaborative research, Politecnico di Milano&amp;rsquo;s

&lt;a href=&#34;https://necst.it&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NECSTLab&lt;/a&gt; and Trend Micro&amp;rsquo;s FTR analyze the protocol in
depth and demonstrate the vulnerability on a real car, with PoC and so on.&lt;/p&gt;
&lt;p&gt;This project started somewhere between 2015 and 2016. Back then, I was an
Assistant Professor at Politecnico di Milano. Together with my colleague

&lt;a href=&#34;https://twitter.com/raistolo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stefano&lt;/a&gt;, I was advising this bright Master
student, 
&lt;a href=&#34;https://www.linkedin.com/in/andreapalanca/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andrea Palanca&lt;/a&gt;, who was
basically &amp;ldquo;breathing cars,&amp;rdquo; and really passionate about car hacking. So it made
a lot of sense to introduce him to 
&lt;a href=&#34;http://www.evenchick.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Eric Evencick&lt;/a&gt;,
who then became part of the project.&lt;/p&gt;
&lt;p&gt;Eric had this idea of looking at the link layer of the CAN protocol, given the
numerous frame-injection attacks popping up here and there. However, we&amp;rsquo;ve
thought, injecting frame in the CAN bus is pretty noisy, and also quite easy to
detect with some smart monitoring. Indeed, knowing the network architecture and
ECUs attached to it (and, let&amp;rsquo;s be honest, they don&amp;rsquo;t change that often even in
a connected car), it&amp;rsquo;s fairly easy to figure out if a frame is out of order, or
simply unexpected.&lt;/p&gt;
&lt;p&gt;Andrea then started to dig into the CAN bus standard, using his own car as
a playground, and quickly came up with a prototype testbed CAN deployment in
the lab, on which he started to explore the effect of flipping &amp;ldquo;the right bit
at the right time&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Alright, enough high-level talking! It&amp;rsquo;s time to take a look at the actual
content.&lt;/p&gt;
&lt;h2 id=&#34;gimme-da-video&#34;&gt;Gimme da Video!&lt;/h2&gt;
&lt;p&gt;In the following short video you can see me presenting the work to an academic
audience. True fact: I&amp;rsquo;ve recorded this while preparing my talk for 
&lt;a href=&#34;https://itsec.cs.uni-bonn.de/dimva2017/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DIMVA
2017&lt;/a&gt;.&lt;/p&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/oajtDFw_t3Q?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;additional-material&#34;&gt;Additional Material&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;re curious to know more:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;for an intermediate-level description, you can read our 
&lt;a href=&#34;https://blog.trendmicro.com/trendlabs-security-intelligence/connected-car-hack/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;blog post&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;for a more in-depth piece, head over to the 
&lt;a href=&#34;https://documents.trendmicro.com/assets/A-Vulnerability-in-Modern-Automotive-Standards-and-How-We-Exploited-It.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;technical brief (PDF)&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;if you&amp;rsquo;re using CAN in your products, you might be interested in our 
&lt;a href=&#34;https://ics-cert.us-cert.gov/alerts/ICS-ALERT-17-209-01&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;disclosure through the ICS-CERT (ICS-ALERT-17-209-01)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Andrea Palanca&lt;/span&gt;, &lt;span&gt;Eric Evenchick&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;/publication/palanca_candos_2017/&#34;&gt;A Stealth, Selective, Link-Layer Denial-of-Service Attack Against Automotive Networks&lt;/a&gt;.
  &lt;em&gt;Proceedings of the 14th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA)&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/palanca_candos_2017/palanca_candos_2017.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/palanca_candos_2017/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Prometheus: Automatic signature generation for WebInject-based banking trojan detection</title>
      <link>/post/prometheus/</link>
      <pubDate>Mon, 12 Jun 2017 17:34:19 +0200</pubDate>
      <guid>/post/prometheus/</guid>
      <description>&lt;p&gt;The goal of this project is to extract signatures that capture the WebInject behavior of
trojans. WebInject-based trojans are still the most popular e-crime tool.&lt;/p&gt;
&lt;p&gt;Prometheus (formerly Zarathustra) is based on a technique that we call web page
differential analysis, which extracts and generates a model of the differences
between a web page visited from an infected (virtual) machine and the very same
page visited from a clean machine. These differences are unavoidable for the
malware to carry out its functionality, and thus allow to create robust
indicators of compromise. We generalize these differences using custom
heuristics to reduce the chances of false positives.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Andrea Continella&lt;/span&gt;, &lt;span&gt;Michele Carminati&lt;/span&gt;, &lt;span&gt;Mario Polino&lt;/span&gt;, &lt;span&gt;Andrea Lanzi&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;/publication/continella_prometheus_article_2017/&#34;&gt;Prometheus: Analyzing WebInject-based information stealers&lt;/a&gt;.
  &lt;em&gt;Journal of Computer Security&lt;/em&gt;.
  
  &lt;p&gt;








  





&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/continella_prometheus_article_2017/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Claudio Criscione&lt;/span&gt;, &lt;span&gt;Fabio Bosatelli&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;
  &lt;/span&gt;
  (2014).
  &lt;a href=&#34;/publication/criscione_zarathustra_2014/&#34;&gt;Zarathustra: Extracting WebInject Signatures from Banking Trojans&lt;/a&gt;.
  &lt;em&gt;Proceedings of the Twelfth Annual International Conference on Privacy, Security and Trust (PST)&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/criscione_zarathustra_2014/criscione_zarathustra_2014.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/criscione_zarathustra_2014/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>The Role of Industrial Routers in Keeping the Future Factory Secure</title>
      <link>/post/industrial-routers/</link>
      <pubDate>Wed, 03 May 2017 12:39:46 +0200</pubDate>
      <guid>/post/industrial-routers/</guid>
      <description>&lt;p&gt;Industrial routers play a very crucial role: a single vulnerability can grant
the attacker access to an entire network of critical machines. In this
research, I&amp;rsquo;ve looked at how easy it is for a hypothetical attacker to find
and enumerate industrial routers, and the security posture of their vendors.&lt;/p&gt;
&lt;p&gt;Industrial routers aren&amp;rsquo;t just regular routers in a rugged case. They are the
gateway to networks of &lt;em&gt;machines&lt;/em&gt;, which usually end up interacting with the
physical world. Think about connected vehicles, factories, robots, and so on.&lt;/p&gt;
&lt;p&gt;While working on a remote access box (another name for &amp;ldquo;industrial router&amp;rdquo;),
during our 
&lt;a href=&#34;http://robosec.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;industrial robots research&lt;/a&gt;, we noticed that
the web-admin panel had an authentication-bypass vulnerability. Upon reporting
the 
&lt;a href=&#34;https://websupport.ewon.biz/support/news/support/ewon-security-enhancement-fw-112s2-0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;vulnerability to the vendor, which patched it right
away&lt;/a&gt;,
we&amp;rsquo;ve wondered: are there other vendors? What&amp;rsquo;s the state of security in this
area?&lt;/p&gt;
&lt;p&gt;After going through the &amp;ldquo;Switches Get Stitches&amp;rdquo; talks (
&lt;a href=&#34;https://www.slideshare.net/44Con/switches-getstitches&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;44CON 2014&lt;/a&gt;, 
&lt;a href=&#34;https://media.ccc.de/v/31c3_-_6196_-_en_-_saal_1_-_201412281130_-_switches_get_stitches_-_eireann_leverett&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;31C3 2014&lt;/a&gt;, 
&lt;a href=&#34;https://www.youtube.com/watch?v=urjKkQaspHQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Black Hat US 2015&lt;/a&gt;),
we had some bad feelings about industrial routers too, so we&amp;rsquo;ve started to
collect technical resources like manuals and firmware update files, and crafted
Shodan and Censys search strings to see how many of these routers were directly
exposed to a casual attacker.&lt;/p&gt;
&lt;p&gt;The first thing that we&amp;rsquo;ve noticed was the abundance of technical information
freely available to the public. Don&amp;rsquo;t get me wrong: I&amp;rsquo;m not advocating in favor
of &amp;ldquo;security through obscurity&amp;rdquo; nor &amp;ldquo;closed source&amp;rdquo;. Once I believe in
openness, I also believe that critical targets like industrial routers (which
are put in front of supposedly critical machinery), shouldn&amp;rsquo;t be &lt;em&gt;that&lt;/em&gt; easy
for a casual attacker to discover. Ironically, marketing brochures required
a registration, whereas firmware and technical manuals were directly indexed by
search engines and publicly accessible.&lt;/p&gt;
&lt;p&gt;Given the security posture of some vendors, we&amp;rsquo;ve decided to take a broad look
at all of them, both from a reconnaissance and vulnerability viewpoint.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re curious, head over to the 
&lt;a href=&#34;https://blog.trendmicro.com/trendlabs-security-intelligence/compromising-industrial-robots/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;full article&lt;/a&gt; on TrendLab&amp;rsquo;s Security Intelligence Blog.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What we Know About Eyepyramid</title>
      <link>/post/eyepyramid/</link>
      <pubDate>Wed, 18 Jan 2017 12:16:11 +0200</pubDate>
      <guid>/post/eyepyramid/</guid>
      <description>&lt;p&gt;The day before the EyePyramid case exploded, I received a confidential email
with a PDF. It was the scanned copy of the court order for the law enforcement
to proceed and arrest the Occhionero brothers. In a few minutes, I noticed that
this leaked document was also circulating on various private mailing lists and
chat groups I&amp;rsquo;m part of. At some point, I received a non-redacted copy.&lt;/p&gt;
&lt;div class=&#34;responsive-wrap&#34;&gt;
	&lt;object data=&#34;ordinanza-occhionero.pdf&#34; type=&#34;application/pdf&#34; style=&#34;margin: 0 auto;height: 100vh;width: 100%;&#34;&gt;
		&lt;embed src=&#34;ordinanza-occhionero.pdf&#34; type=&#34;application/pdf &#34;style=&#34;margin: 0 auto;height: 100vh;width: 100%;&#34;&gt;
			&lt;em&gt;It seems that your browser cannot display the PDF file; Please use this &lt;a href=&#34;ordinanza-occhionero.pdf&#34;&gt;&lt;strong&gt;link&lt;/strong&gt; &lt;/a&gt;
			instead. Thanks!&lt;/em&gt;
	&lt;/object&gt;
&lt;/div&gt;

&lt;p&gt;I typically do not work on e-crime investigation cases, but while reading the
court order I felt that something was not completely right. Moreover, the case
was in Italy, my home country, which motivated me to look at it. Then, some
colleagues from Trend Micro Italy contacted me with questions coming from our
clients (for which, back then, I couldn&amp;rsquo;t answer yet). So, at the end of the
day I decided to dive in!&lt;/p&gt;
&lt;h3 id=&#34;puzzling-facts-in-the-court-order&#34;&gt;Puzzling Facts in the Court Order&lt;/h3&gt;
&lt;p&gt;I skimmed through the court order and was surprised by the vast amount of
technical evidence provided to support the accusations. Email addresses (in
clear or easy to guess when redacted), IP addresses, domain names. So detailed
that I could basically write a Yara rule to hunt for malware samples, without
even looking at a single binary.&lt;/p&gt;
&lt;p&gt;And then, the part that puzzled me most. The author of the malware used
a licensed software library and allegedly &lt;em&gt;purchased the license under the name
of Giulio Occhionero&lt;/em&gt; (one of the two brothers). It&amp;rsquo;s like, leaving your name
on the crime scene!&lt;/p&gt;
&lt;h3 id=&#34;almost-live-reversing&#34;&gt;(Almost) Live Reversing&lt;/h3&gt;
&lt;p&gt;After getting my hands on some samples (yes, with Yara hunting rules based on
the court order), things escalated quickly, and found myself looking at nearly
250 samples. With the help of my fine colleagues, we&amp;rsquo;ve drawn rough, big
picture of the whole scheme and started to find confirmatory evidence.&lt;/p&gt;
&lt;p&gt;In a few hours, people on Twitter and other social networks started to follow
the case closely, comment on it, give their own views. Given some confusion,
I felt the urge to publish a list of &amp;ldquo;cold, simple, yet true&amp;rdquo; technical facts.
So I&amp;rsquo;ve spun up a GitHub Gist (now deleted), which then evolved in a 
&lt;a href=&#34;https://github.com/eyepyramid/eyepyramid&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;full
repository&lt;/a&gt; (now not updated
anymore), and finally 
&lt;a href=&#34;https://medium.com/@phretor/cosa-sappiamo-su-eyepyramid-61b5b88c63b8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a post on Medium (in
Italian)&lt;/a&gt;.
Results were popping up rapidly, so I found myself unable to keep up with the
pace, and decided to stop &amp;ldquo;live reversing&amp;rdquo; the samples, set aside some time and
prepare two comprehensive posts for TrendLab&amp;rsquo;s Intelligence Blog, which my
employer was very happy to release in no time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jan 18, 2017 - 
&lt;a href=&#34;https://blog.trendmicro.com/trendlabs-security-intelligence/uncovering-inner-workings-eyepyramid/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Uncovering the Inner Workings of EyePyramid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jan 11, 2017 - 
&lt;a href=&#34;https://blog.trendmicro.com/trendlabs-security-intelligence/eye-storm-look-eyepyramid-malware-supposedly-used-high-profile-hacks-italy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Eye of the Storm: A Look at EyePyramid, the Malware Supposedly Used in High-Profile Hacks in Italy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;summary-of-the-case&#34;&gt;Summary of the Case&lt;/h3&gt;
&lt;p&gt;On the one hand, the original source code had gone through only very mild
modifications (e.g., not all variants are able to exfiltrate Skype
conversations, C&amp;amp;C and dropzones, compiler version, and protection mechanisms).
On the other hand, the computer(s) used to build the various versions over the
years seemed to be in line with the evolution of Microsoft developer tools
(based on the progression of the compiler version) and software-protection
tools (as seen on the recent substitution of Skater plus Dotfuscator with the
more powerful ConfuserEx). This indicates that the actors behind this operation
knew what they were doing. Of course, this was (and still) far from being an advanced
or targeted piece of malware.&lt;/p&gt;
&lt;p&gt;Apart from this, the origins of EyePyramid’s malware and its attribution remain
a mystery. While the license key registered to Giulio Occhionero’s name can be
considered as strong evidence, it is unclear why a malware author would bother
using (simple yet not so trivial) mechanisms to cover their traces (e.g.,
obfuscation, packing, encryption, disabling security tools), and then
mistakenly embed the license key under his name in all of the main variants.
Moreover, an analysis of the domain-to-IP historical data of the domain names
listed in the court order reveals domains named &lt;code&gt;occhionero.com&lt;/code&gt; and
&lt;code&gt;occhionero.info&lt;/code&gt;, which is again another oddity.&lt;/p&gt;
&lt;h3 id=&#34;latest-update-just-another-oddity&#34;&gt;Latest Update (Just Another Oddity)&lt;/h3&gt;
&lt;p&gt;I received an unexpected email message from someone I&amp;rsquo;ve never heard before.
Despite the author of this email is not known in the cyber security community
(he presented himself as a PhD Student in medicine at Stanford), he took the
time (and money) to verify every single email address written in my analysis
and in the court order.&lt;/p&gt;
&lt;p&gt;Using LeakedSource (now taken down) he had found that one of the compromised
email addresses (&lt;code&gt;lu_1974[@]hotmail.com&lt;/code&gt;, which is linked to EyePyramid) was
used to register on various dating sites. LeakedSource was borderline websites
that hosted stolen information, including usernames and
passwords.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“this is probably just a coincidence”&lt;/em&gt; he said but &lt;em&gt;“Giulio also used his
&lt;code&gt;@westlands.com&lt;/code&gt; address to register to the same dating sites.”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Anyways, I&amp;rsquo;ve replied back, thanking him for his work. Then I&amp;rsquo;ve asked him why
a Stanford PhD Student in medicine was so interested in such “niche” case
(unfolded from the other side of the world), and how he knew that Giulio
Occhionero had used his &lt;code&gt;@westlands.com&lt;/code&gt; address to register to the same dating
sites, because I could not find any evidence about it&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve never gotten a reply.&lt;/p&gt;
&lt;h3 id=&#34;media&#34;&gt;Media&lt;/h3&gt;
&lt;p&gt;After getting in touch with 
&lt;a href=&#34;https://twitter.com/carolafrediani&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Carola
Frediani&lt;/a&gt;, who did a very good job
consolidating all the facts for La Stampa (
&lt;a href=&#34;http://www.lastampa.it/2017/01/12/italia/cronache/tutti-i-dettagli-e-i-misteri-di-eyepyramid-S3vOtTe6smhbJbBlrogpcJ/pagina.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutti i dettagli e i misteri di
EyePyramid&lt;/a&gt;),
I happily joined the hacker&amp;rsquo;s corner at the International Journalism Festival
2017 in Perugia, a few months later, in a panel moderated by Carola. Here&amp;rsquo;s
the recording of the panel.&lt;/p&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/icgJavQqICM?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Mobile (Android) Ransomware</title>
      <link>/post/mobile-ransomware/</link>
      <pubDate>Thu, 08 Dec 2016 01:32:15 +0200</pubDate>
      <guid>/post/mobile-ransomware/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve started this project while advising a Master student who was interested
in machine learning. As I&amp;rsquo;ve been using machine learning since around 2006, I
was immediately hooked by the idea of using it to determine whether an
Android app was trying to lock the target device as part of a ransomware
scheme.&lt;/p&gt;
&lt;p&gt;There are three core characteristics that are unavoidable for any ransomware
scheme, which can be all boiled down to the &amp;ldquo;business&amp;rdquo; need of &amp;ldquo;being noisy&amp;rdquo;
and evident. It&amp;rsquo;s true right? For the first time we see malware that is no
longer trying to hide. Instead, it needs to loudly announce its presence to the
victim, in order for the business model to work. If the victim is not aware of
what is happening and is not effectively guided to the payment screen, the
infection is useless.&lt;/p&gt;
&lt;p&gt;Therefore, any ransomware needs to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;encrypt or lock access to important data,&lt;/li&gt;
&lt;li&gt;announce its presence to the user and,&lt;/li&gt;
&lt;li&gt;guide them through the payment options.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These three features &lt;strong&gt;have to be implemented&lt;/strong&gt; by a ransomware sample, and
thus have to be visible somehow in the code. Around this key observation,
together with the evil genius 
&lt;a href=&#34;https://www.andronio.me/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nicolò Andronio&lt;/a&gt; (the
aforementioned Master student) and my partner-in-crime

&lt;a href=&#34;https://twitter.com/raistolo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stefano&lt;/a&gt;, we devised and open-sourced

&lt;a href=&#34;https://github.com/necst/heldroid&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HelDroid&lt;/a&gt;, a fully automatic APK analyzer
that, using static flow analysis, detects whether an app contains evidence of
ransomware behavior.&lt;/p&gt;
&lt;p&gt;Earlier this summer I&amp;rsquo;ve joined 
&lt;a href=&#34;https://www.trendmicro.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trend Micro&lt;/a&gt;&amp;rsquo;s
research team, and immediately got my hands onto MARS, its 
&lt;a href=&#34;https://mars.trendmicro.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mobile App
Reputation Service&lt;/a&gt;, which allowed me to build
a good retrospective view of how Android ransomware have evolved.&lt;/p&gt;
&lt;p&gt;This work granted me a speaking slot at the Black Hat Europe Briefings, where
I had the opportunity to present the results to a room packed with attendees.
Was a great experience!&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re curious, you can read a summarized version of the research in these
two blog posts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://blog.trendmicro.com/trendlabs-security-intelligence/mobile-ransomware-pocket-sized-badness/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mobile Ransomware: Pocket-Sized Badness&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://blog.trendmicro.com/trendlabs-security-intelligence/mobile-ransomware-protect/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mobile Ransomware: How to Protect Against It&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s the 
&lt;a href=&#34;https://web.archive.org/web/20180216035340/http://ransom.mobi/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;web service (archived)&lt;/a&gt; in case you want to check it out.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;
  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Chenghyu Zheng&lt;/span&gt;, &lt;span&gt;Nicola Della Rocca&lt;/span&gt;, &lt;span&gt;Niccolò Andronio&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;, &lt;span&gt;Maggi Federico&lt;/span&gt;
  &lt;/span&gt;
  (2016).
  &lt;a href=&#34;/publication/zheng_greateatlon_2016/&#34;&gt;GreatEatlon: Fast, Static Detection of Mobile Ransomware&lt;/a&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/zheng_greateatlon_2016/zheng_greateatlon_2016.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/zheng_greateatlon_2016/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Niccolò Andronio&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;
  &lt;/span&gt;
  (2015).
  &lt;a href=&#34;/publication/andronio_heldroid_2015/&#34;&gt;HelDroid: Dissecting and Detecting Mobile Ransomware&lt;/a&gt;.
  &lt;em&gt;International Symposium on Research in Attacks, Intrusions and Defenses (RAID)&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/andronio_heldroid_2015/andronio_heldroid_2015.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/andronio_heldroid_2015/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Banksealer: Automatic Banking Fraud Detection</title>
      <link>/post/banksealer/</link>
      <pubDate>Sun, 05 Jun 2016 17:34:12 +0200</pubDate>
      <guid>/post/banksealer/</guid>
      <description>&lt;p&gt;We started this project because we wanted to analyze banking and credit-card
transactions and, with as little knowledge as possible, predict whether new
ones are fraudulent or not (e.g., due to a banking trojan working on the
victim’s computer, made by a cyber criminal with stolen credentials).&lt;/p&gt;
&lt;p&gt;BankSealer is based on lightweight statistical learning on feature models
(e.g., amount, timestamp, recipient country, description) extracted by each
transaction. BankSealer is currently deployed at one of the largest Italian
banks and has been proven effective at detecting frauds, to the point that my
co-authors have created a startup out of it!&lt;/p&gt;
&lt;p&gt;Banksealer is now a fintech startup: 
&lt;a href=&#34;https://banksealer.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://banksealer.com&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;
  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Federico Maggi&lt;/span&gt;
  &lt;/span&gt;
  (2016).
  &lt;a href=&#34;/talk/maggi_banksealer_talk_2016/&#34;&gt;Fast and Transparent Online Banking Fraud Detection and Investigation&lt;/a&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/talk/maggi_banksealer_talk_2016/maggi_banksealer_talk_2016.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/talk/maggi_banksealer_talk_2016/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Michele Carminati&lt;/span&gt;, &lt;span&gt;Roberto Caron&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Ilenia Epifani&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;
  &lt;/span&gt;
  (2014).
  &lt;a href=&#34;/publication/carminati_banksealer_2014/&#34;&gt;BankSealer: An Online Banking Fraud Analysis and Decision Support System&lt;/a&gt;.
  &lt;em&gt;ICT Systems Security and Privacy Protection&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/carminati_banksealer_2014/carminati_banksealer_2014.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/carminati_banksealer_2014/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Droydseuss: Android Malware Tracking and Intelligence</title>
      <link>/post/droydseuss/</link>
      <pubDate>Fri, 05 Feb 2016 17:34:04 +0200</pubDate>
      <guid>/post/droydseuss/</guid>
      <description>&lt;p&gt;We wanted to create a malware tracker similar to ZeusTracker, but for mobile bankers. So we built a tool, DroydSeuss, which uses static analysis to extract relevant C&amp;amp;C endpoints (e.g., phone number, web URLs) and monitors them by running each sample in a sandbox on a daily basis.&lt;/p&gt;
&lt;p&gt;On top of this, DroydSeuss attaches meta data to both C&amp;amp;C endpoints and malware samples (e.g., country, code feature) that are used to mine association rules. These rules are automatically extracted and can tell useful information such as “there is a group of malware samples that seem to be coming from the same author spreading in a certain country”.&lt;/p&gt;
&lt;p&gt;We made the tool public and immediately attracted other researcher’s attention. Thanks to the data feed produced by DroydSeuss we were able to find (and confirm) one malware campaign spreading against Chinese and Korean bank customers and to discover a strange, rare sample that was using Baidu as a C&amp;amp;C.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Update: Jun 6th, 2020)&lt;/em&gt; We decided not to maintain the web service anymore. We only keep the URL here for hystorical reasons: 
&lt;a href=&#34;http://droydseuss.necst.it&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://droydseuss.necst.it&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;
  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Alberto Coletta&lt;/span&gt;, &lt;span&gt;Victor Van Der Veen&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;
  &lt;/span&gt;
  (2016).
  &lt;a href=&#34;/publication/coletta_droydseuss_2016/&#34;&gt;DroydSeuss: A Mobile Banking Trojan Tracker - Short Paper&lt;/a&gt;.
  &lt;em&gt;Financial Cryptography and Data Security&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/coletta_droydseuss_2016/coletta_droydseuss_2016.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/coletta_droydseuss_2016/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Federico Maggi&lt;/span&gt;
  &lt;/span&gt;
  (2015).
  &lt;a href=&#34;/talk/maggi_droydseuss_talk_2015/&#34;&gt;A walk through the construction of the first mobile malware tracker&lt;/a&gt;.
  
  &lt;p&gt;








  





&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/talk/maggi_droydseuss_talk_2015/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;

&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Grab &#39;n Run: Secure dynamic code loading for Android</title>
      <link>/post/grabnrun/</link>
      <pubDate>Wed, 05 Aug 2015 17:34:45 +0200</pubDate>
      <guid>/post/grabnrun/</guid>
      <description>&lt;p&gt;A simple and effective Java Library that you can easily add to your Android
projects to perform secure dynamic class loading operations.&lt;/p&gt;
&lt;p&gt;The standard

&lt;a href=&#34;https://developer.android.com/reference/dalvik/system/DexClassLoader.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DexClassLoader&lt;/a&gt; is not secure, so one single mistake could open the application (and, therefore,
the entire device) to serious security vulnerabilities, such as remote code
execution. The main goal of Grab&amp;rsquo;s Run is to offer an alternative to the native
Android APIs, and its design enforces that even the most inexperienced
developer cannot perform well-known, serious mistakes.&lt;/p&gt;
&lt;p&gt;Check out the source code: 
&lt;a href=&#34;https://github.com/lukeFalsina/Grab-n-Run&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;github.com/lukeFalsina/Grab-n-Run&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Luca Falsina&lt;/span&gt;, &lt;span&gt;Yanick Fratantonio&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;, &lt;span&gt;Christopher Kruegel&lt;/span&gt;, &lt;span&gt;Giovanni Vigna&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;
  &lt;/span&gt;
  (2015).
  &lt;a href=&#34;/publication/falsina_grabnrun_2015/&#34;&gt;Grab &amp;#39;n Run: Secure and Practical Dynamic Code Loading for Android Applications&lt;/a&gt;.
  &lt;em&gt;Proceedings of the 31st Annual Computer Security Applications Conference&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/falsina_grabnrun_2015/falsina_grabnrun_2015.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/falsina_grabnrun_2015/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Internet of Things. Applicazioni, sicurezza e riservatezza dei dati personali</title>
      <link>/post/iot-sec-priv/</link>
      <pubDate>Mon, 26 Jan 2015 11:53:30 +0200</pubDate>
      <guid>/post/iot-sec-priv/</guid>
      <description>&lt;p&gt;Sono stato invitato dal Garante per la Protezione dei Dati alla 
&lt;a href=&#34;http://www.garanteprivacy.it/web/guest/home/docweb/-/docweb-display/docweb/3654813&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;giornata europea della privacy&lt;/a&gt;, con richiesta di fare un po&amp;rsquo; di chiarezza sul fenomeno IoT. Questo articolo è una versione &amp;ldquo;verbosa&amp;rdquo; del mio intervento, che si incentra sui tre fattori che, secondo me, hanno contribuito a dar vita a questo fenomeno: tecnologia accessibile a basso costo, moltitudine di scenari applicativi e media.&lt;/p&gt;
&lt;p&gt;Si tratta di un post piuttosto lungo: 
&lt;a href=&#34;https://medium.com/@phretor/internet-of-things-sicurezza-e-riservatezza-dei-dati-personali-f18a13dbe1cf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;lo trovate su Medium&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AndRadar: Mobile app Marketplace Monitoring and Reputation Analysis</title>
      <link>/post/andradar/</link>
      <pubDate>Sat, 07 Jun 2014 11:25:36 +0200</pubDate>
      <guid>/post/andradar/</guid>
      <description>&lt;p&gt;The main goal of this project is to provide a dashboard to analyze and monitor the spreading of
Android malware in marketplaces. AndRadar uses lightweight fingerprints to
lookup malware samples without the need to download them from the markets.&lt;/p&gt;
&lt;p&gt;Once a matching app is found, AndRadar tracks its page, developer, and any
kind of meta data associated to it. AndRadar’s data is then crunched into a
set of indicators that summarize, for example, the efficiency of a malware
author in publishing its app, the speed of the market in responding to
threats, etc., and provide an overall reputation of each developer, market
and app. By combining data coming from different marketplaces, AndRadar can
track spreading campaigns also across markets. No such tool like AndRadar
exists so far, so we released it to the public.&lt;/p&gt;
&lt;p&gt;The (unmaintained) web application is at: 
&lt;a href=&#34;http://andradar.hosting.necst.it&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://andradar.hosting.necst.it&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Martina Lindorfer&lt;/span&gt;, &lt;span&gt;Stamatis Volanis&lt;/span&gt;, &lt;span&gt;Alessandro Sisto&lt;/span&gt;, &lt;span&gt;Matthias Neugschwandtner&lt;/span&gt;, &lt;span&gt;Elias Athanasopoulos&lt;/span&gt;, &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Christian Platzer&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;, &lt;span&gt;Sotiris Ioannidis&lt;/span&gt;
  &lt;/span&gt;
  (2014).
  &lt;a href=&#34;/publication/lindorfer_andradar_2014/&#34;&gt;AndRadar: Fast Discovery of Android Applications in Alternative Markets&lt;/a&gt;.
  &lt;em&gt;Detection of Intrusions and Malware, and Vulnerability Assessment&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/lindorfer_andradar_2014/lindorfer_andradar_2014.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/lindorfer_andradar_2014/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>iSnoop: Automatic Eavesdropping from Touchscreen Keyboards</title>
      <link>/post/isnoop/</link>
      <pubDate>Thu, 01 Dec 2011 17:33:08 +0200</pubDate>
      <guid>/post/isnoop/</guid>
      <description>&lt;p&gt;Spying on a person is an easy and effective method to obtain sensitive
information, even when the victim is well protected against common digital
attacks. Modern mobile devices allow people to perform some information
sensitive actions in unsafe places, where anyone could easily observe the
victim while typing.&lt;/p&gt;
&lt;p&gt;What if your mobile phone has a cool touchscreen
interface that gives you graphical feedback as you type (iPhone, Android,
BlackBerry Torch)? Does it make shoulder surfing easier or, worse,
automatable? We believe so, and to demonstrate it, we developed a practical
shoulder surfing attack that automatically reconstructs the sequence of
keystrokes by aiming a camera at the target touchscreen while the victim is
typing.&lt;/p&gt;
&lt;h2 id=&#34;demo&#34;&gt;Demo&lt;/h2&gt;

    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/t9BxB3dO0KQ?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Alberto Volpatto&lt;/span&gt;, &lt;span&gt;Simone Gasparini&lt;/span&gt;, &lt;span&gt;Giacomo Boracchi&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;
  &lt;/span&gt;
  (2011).
  &lt;a href=&#34;/publication/maggi_iclearshotposter_2011/&#34;&gt;POSTER: Fast, Automatic iPhone Shoulder Surfing&lt;/a&gt;.
  &lt;em&gt;Proceedings of the 18th Conference on Computer and Communication Security (CCS)&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/maggi_iclearshotposter_2011/maggi_iclearshotposter_2011.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/maggi_iclearshotposter_2011/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Alberto Volpatto&lt;/span&gt;, &lt;span&gt;Simone Gasparini&lt;/span&gt;, &lt;span&gt;Giacomo Boracchi&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;
  &lt;/span&gt;
  (2011).
  &lt;a href=&#34;/publication/maggi_iclearshot_2011/&#34;&gt;A Fast Eavesdropping Attack Against Touchscreens&lt;/a&gt;.
  &lt;em&gt;Proceedings of the 7th International Conference on Information Assurance and Security (IAS)&lt;/em&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/maggi_iclearshot_2011/maggi_iclearshot_2011.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/maggi_iclearshot_2011/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;



  &lt;div class=&#34;pub-list-item&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  
  &lt;span&gt;Federico Maggi&lt;/span&gt;, &lt;span&gt;Alberto Volpatto&lt;/span&gt;, &lt;span&gt;Simone Gasparini&lt;/span&gt;, &lt;span&gt;Giacomo Boracchi&lt;/span&gt;, &lt;span&gt;Stefano Zanero&lt;/span&gt;
  &lt;/span&gt;
  (2010).
  &lt;a href=&#34;/publication/maggi_iclearshot_tr_2010/&#34;&gt;Don&amp;#39;t touch a word! A practical input eavesdropping attack against mobile touchscreen devices&lt;/a&gt;.
  
  &lt;p&gt;








  



&lt;a class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm&#34; href=&#34;/publication/maggi_iclearshot_tr_2010/maggi_iclearshot_tr_2010.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;button type=&#34;button&#34; class=&#34;btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/maggi_iclearshot_tr_2010/cite.bib&#34;&gt;
  Cite
&lt;/button&gt;














&lt;/p&gt;

  
  
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
