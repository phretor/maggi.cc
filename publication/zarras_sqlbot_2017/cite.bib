
@InProceedings{	  zarras_sqlbot_2017,
  abstract	= {It could be argued that without search engines, the web
		  would have never grown to the size that it has today. To
		  achieve maximum coverage and provide relevant results,
		  search engines employ large armies of autonomous crawlers
		  that continuously scour the web, following links, indexing
		  content, and collecting features that are then used to
		  calculate the ranking of each page. In this paper, we
		  describe how autonomous crawlers can be abused by attackers
		  to exploit vulnerabilities on thirdparty websites while
		  hiding the true origin of the attacks. Moreover, we show
		  how certain vulnerabilities on websites that are currently
		  deemed unimportant, can be abused in a way that would allow
		  an attacker to arbitrarily boost the rankings of malicious
		  websites in the search results of popular search engines.
		  Motivated by the potentials of these vulnerabilities, we
		  propose a series of preventive and defensive
		  countermeasures that website owners and search engines can
		  adopt to minimize, or altogether eliminate, the effects of
		  crawler-abusing attacks.},
  author	= {Zarras, Apostolis and Maggi, Federico},
  booktitle	= {Proceedings of the 15th Annual International Conference on
		  Privacy, Security and Trust (PST)},
  date		= {2017-08-28},
  doi		= {10.1109/PST.2017.00049},
  file		= {files/papers/conference-papers/zarras_sqlbot_2017.pdf},
  isbn		= {978-1-5386-2487-6},
  location	= {Calgary, Canada},
  pages		= {355--35509},
  publisher	= {IEEE Computer Society},
  shorttitle	= {SQLBot},
  title		= {Hiding Behind the Shoulders of Giants: Abusing Crawlers
		  for Indirect Web Attacks}
}
